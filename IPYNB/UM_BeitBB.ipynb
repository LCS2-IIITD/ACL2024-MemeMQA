{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UM BEiT-BERT-BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn.functional as F\n",
    "from torch import optim, nn\n",
    "from torchvision import models, transforms\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "import os, sys\n",
    "sys.path.append('/workout/early-stopping-pytorch')\n",
    "from pytorchtools import EarlyStopping\n",
    "from tqdm import tqdm,trange\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siddhant20247/ENTER/envs/py39/lib/python3.9/site-packages/transformers/models/beit/feature_extraction_beit.py:28: FutureWarning: The class BeitFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use BeitImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BeitModel, AutoFeatureExtractor\n",
    "from transformers import BertTokenizer\n",
    "from transformers import VisualBertForPreTraining\n",
    "from transformers import VisionEncoderDecoderModel\n",
    "from transformers.modeling_outputs import BaseModelOutput\n",
    "BERTtokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"microsoft/beit-base-patch16-224-pt22k\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemeMQACorpus(torch.utils.data.Dataset):\n",
    "    \"\"\"Uses jsonl data to preprocess and serve \n",
    "    dictionary of multimodal tensors for model input.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path,\n",
    "        img_dir,\n",
    "        mode=None,\n",
    "        balance=False,\n",
    "        dev_limit=None,\n",
    "        random_state=0,\n",
    "    ):\n",
    "\n",
    "        self.samples_frame = pd.read_json(\n",
    "            data_path\n",
    "        )\n",
    "        \n",
    "        self.samples_frame = self.samples_frame[self.samples_frame[\"meme_image\"].notnull()]\n",
    "        self.samples_frame = self.samples_frame[self.samples_frame[\"ocr\"].notnull()]\n",
    "        self.samples_frame = self.samples_frame[self.samples_frame[\"entity\"].notnull()]\n",
    "        self.samples_frame = self.samples_frame[self.samples_frame[\"explanation\"].notnull()]\n",
    "        if mode == \"test\":\n",
    "            self.samples_frame = self.samples_frame[self.samples_frame[\"explanation1\"].notnull()]\n",
    "\n",
    "\n",
    "        self.samples_frame = self.samples_frame.reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "        self.samples_frame.image = self.samples_frame.apply(\n",
    "            lambda row: (img_dir + '/' + row.meme_image), axis=1\n",
    "        )\n",
    "        \n",
    "        self.image_transform = Resize((256,256))\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"This method is called when you do len(instance) \n",
    "        for an instance of this class.\n",
    "        \"\"\"\n",
    "        return len(self.samples_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"This method is called when you do instance[key] \n",
    "        for an instance of this class.\n",
    "        \"\"\"\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = self.samples_frame.loc[idx, \"meme_image\"]  \n",
    "\n",
    "    \n",
    "#         ***Get Beit input data***\n",
    "        file_name = data_dir + self.samples_frame.loc[idx, \"meme_image\"]\n",
    "        beit_image_data = Image.open(file_name)\n",
    "        if beit_image_data.mode != 'RGB':\n",
    "            beit_image_data = beit_image_data.convert('RGB')            \n",
    "        beit_inputs = feature_extractor(images=beit_image_data, return_tensors=\"pt\", padding=True)\n",
    "        beit_inputs['pixel_values'] = beit_inputs['pixel_values'].squeeze()\n",
    "        bert_inputs =self.samples_frame.loc[idx, \"question\"]  + \"\\n Options: \" + self.samples_frame.loc[idx, \"optC\"]\n",
    "        decoder_text = \"Answer: \" + self.samples_frame.loc[idx, \"entity\"] + \" BECAUSE \" + self.samples_frame.loc[idx, \"explanation\"]\n",
    "\n",
    "        sample = {\n",
    "                \"img_name\": img_name,        \n",
    "                \"bert_inputs\": bert_inputs,\n",
    "                \"beit_inputs\": beit_inputs,\n",
    "                \"decoder_text\": decoder_text\n",
    "            }\n",
    "        try:\n",
    "            sample[\"decoder_text1\"] = \"Answer: \" + self.samples_frame.loc[idx, \"entity\"] + \" BECAUSE \" + self.samples_frame.loc[idx, \"explanation1\"]\n",
    "        except:\n",
    "            pass\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2286447/1761090260.py:33: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  self.samples_frame.image = self.samples_frame.apply(\n",
      "/tmp/ipykernel_2286447/1761090260.py:33: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  self.samples_frame.image = self.samples_frame.apply(\n"
     ]
    }
   ],
   "source": [
    "BS = 4\n",
    "train_path = \"../data/data_train_role.json\"\n",
    "dev_path = \"../data/data_val_role.json\"\n",
    "data_dir = \"../../HVV/datafiles/images/\"\n",
    "hm_dataset_train = MemeMQACorpus(train_path, data_dir)\n",
    "dataloader_train = DataLoader(hm_dataset_train, batch_size=BS,\n",
    "                        shuffle=True, num_workers=0)\n",
    "hm_dataset_val = MemeMQACorpus(dev_path, data_dir)\n",
    "dataloader_val = DataLoader(hm_dataset_val, batch_size=BS,\n",
    "                        shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "data_time = AverageMeter('Data', ':6.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at microsoft/beit-base-patch16-224-pt22k were not used when initializing BeitModel: ['layernorm.weight', 'lm_head.bias', 'layernorm.bias', 'lm_head.weight']\n",
      "- This IS expected if you are initializing BeitModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BeitModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertLMHeadModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.self.query.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MM(\n",
       "  (model_bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (model_encdec): VisionEncoderDecoderModel(\n",
       "    (encoder): BeitModel(\n",
       "      (embeddings): BeitEmbeddings(\n",
       "        (patch_embeddings): BeitPatchEmbeddings(\n",
       "          (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (encoder): BeitEncoder(\n",
       "        (relative_position_bias): BeitRelativePositionBias()\n",
       "        (layer): ModuleList(\n",
       "          (0): BeitLayer(\n",
       "            (attention): BeitAttention(\n",
       "              (attention): BeitSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BeitSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BeitIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BeitOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (drop_path): Identity()\n",
       "            (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (1): BeitLayer(\n",
       "            (attention): BeitAttention(\n",
       "              (attention): BeitSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BeitSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BeitIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BeitOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (drop_path): BeitDropPath(p=0.00909090880304575)\n",
       "            (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (2): BeitLayer(\n",
       "            (attention): BeitAttention(\n",
       "              (attention): BeitSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BeitSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BeitIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BeitOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (drop_path): BeitDropPath(p=0.0181818176060915)\n",
       "            (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (3): BeitLayer(\n",
       "            (attention): BeitAttention(\n",
       "              (attention): BeitSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BeitSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BeitIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BeitOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (drop_path): BeitDropPath(p=0.027272727340459824)\n",
       "            (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (4): BeitLayer(\n",
       "            (attention): BeitAttention(\n",
       "              (attention): BeitSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BeitSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BeitIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BeitOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (drop_path): BeitDropPath(p=0.036363635212183)\n",
       "            (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (5): BeitLayer(\n",
       "            (attention): BeitAttention(\n",
       "              (attention): BeitSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BeitSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BeitIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BeitOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (drop_path): BeitDropPath(p=0.045454543083906174)\n",
       "            (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (6): BeitLayer(\n",
       "            (attention): BeitAttention(\n",
       "              (attention): BeitSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BeitSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BeitIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BeitOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (drop_path): BeitDropPath(p=0.054545458406209946)\n",
       "            (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (7): BeitLayer(\n",
       "            (attention): BeitAttention(\n",
       "              (attention): BeitSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BeitSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BeitIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BeitOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (drop_path): BeitDropPath(p=0.06363636255264282)\n",
       "            (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (8): BeitLayer(\n",
       "            (attention): BeitAttention(\n",
       "              (attention): BeitSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BeitSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BeitIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BeitOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (drop_path): BeitDropPath(p=0.0727272778749466)\n",
       "            (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (9): BeitLayer(\n",
       "            (attention): BeitAttention(\n",
       "              (attention): BeitSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BeitSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BeitIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BeitOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (drop_path): BeitDropPath(p=0.08181818574666977)\n",
       "            (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (10): BeitLayer(\n",
       "            (attention): BeitAttention(\n",
       "              (attention): BeitSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BeitSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BeitIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BeitOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (drop_path): BeitDropPath(p=0.09090909361839294)\n",
       "            (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (11): BeitLayer(\n",
       "            (attention): BeitAttention(\n",
       "              (attention): BeitSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BeitSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BeitIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BeitOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (drop_path): BeitDropPath(p=0.10000000149011612)\n",
       "            (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layernorm): Identity()\n",
       "      (pooler): BeitPooler(\n",
       "        (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (decoder): BertLMHeadModel(\n",
       "      (bert): BertModel(\n",
       "        (embeddings): BertEmbeddings(\n",
       "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (token_type_embeddings): Embedding(2, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): BertEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (crossattention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (1): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (crossattention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (2): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (crossattention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (3): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (crossattention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (4): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (crossattention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (5): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (crossattention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (6): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (crossattention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (7): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (crossattention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (8): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (crossattention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (9): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (crossattention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (10): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (crossattention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (11): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (crossattention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (cls): BertOnlyMLMHead(\n",
       "        (predictions): BertLMPredictionHead(\n",
       "          (transform): BertPredictionHeadTransform(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (transform_act_fn): GELUActivation()\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import VisionEncoderDecoderModel\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from pathlib import Path\n",
    "class MM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MM, self).__init__()        \n",
    "        self.model_bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.model_encdec = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(\"microsoft/beit-base-patch16-224-pt22k\", \"bert-base-uncased\")\n",
    "        self.model_encdec.config.decoder_start_token_id = BERTtokenizer.cls_token_id\n",
    "        self.model_encdec.config.pad_token_id = BERTtokenizer.pad_token_id\n",
    "        \n",
    "    def forward(self, pixel_values, bert_input_ids, bert_attention_mask, bert_token_type_ids, dec_labels):\n",
    "        bert_encoder_outputs = self.model_bert(input_ids = bert_input_ids, attention_mask = bert_attention_mask, token_type_ids = bert_token_type_ids, output_hidden_states=True, return_dict=True)\n",
    "        enc_dec_out = self.model_encdec(pixel_values=pixel_values, encoder_outputs=bert_encoder_outputs, labels=dec_labels, output_hidden_states=True, return_dict=True)\n",
    "        return enc_dec_out      \n",
    "\n",
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "model = MM()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------+------------+\n",
      "|                                      Modules                                      | Parameters |\n",
      "+-----------------------------------------------------------------------------------+------------+\n",
      "|                    model_bert.embeddings.word_embeddings.weight                   |  23440896  |\n",
      "|                  model_bert.embeddings.position_embeddings.weight                 |   393216   |\n",
      "|                 model_bert.embeddings.token_type_embeddings.weight                |    1536    |\n",
      "|                       model_bert.embeddings.LayerNorm.weight                      |    768     |\n",
      "|                        model_bert.embeddings.LayerNorm.bias                       |    768     |\n",
      "|               model_bert.encoder.layer.0.attention.self.query.weight              |   589824   |\n",
      "|                model_bert.encoder.layer.0.attention.self.query.bias               |    768     |\n",
      "|                model_bert.encoder.layer.0.attention.self.key.weight               |   589824   |\n",
      "|                 model_bert.encoder.layer.0.attention.self.key.bias                |    768     |\n",
      "|               model_bert.encoder.layer.0.attention.self.value.weight              |   589824   |\n",
      "|                model_bert.encoder.layer.0.attention.self.value.bias               |    768     |\n",
      "|              model_bert.encoder.layer.0.attention.output.dense.weight             |   589824   |\n",
      "|               model_bert.encoder.layer.0.attention.output.dense.bias              |    768     |\n",
      "|            model_bert.encoder.layer.0.attention.output.LayerNorm.weight           |    768     |\n",
      "|             model_bert.encoder.layer.0.attention.output.LayerNorm.bias            |    768     |\n",
      "|                model_bert.encoder.layer.0.intermediate.dense.weight               |  2359296   |\n",
      "|                 model_bert.encoder.layer.0.intermediate.dense.bias                |    3072    |\n",
      "|                   model_bert.encoder.layer.0.output.dense.weight                  |  2359296   |\n",
      "|                    model_bert.encoder.layer.0.output.dense.bias                   |    768     |\n",
      "|                 model_bert.encoder.layer.0.output.LayerNorm.weight                |    768     |\n",
      "|                  model_bert.encoder.layer.0.output.LayerNorm.bias                 |    768     |\n",
      "|               model_bert.encoder.layer.1.attention.self.query.weight              |   589824   |\n",
      "|                model_bert.encoder.layer.1.attention.self.query.bias               |    768     |\n",
      "|                model_bert.encoder.layer.1.attention.self.key.weight               |   589824   |\n",
      "|                 model_bert.encoder.layer.1.attention.self.key.bias                |    768     |\n",
      "|               model_bert.encoder.layer.1.attention.self.value.weight              |   589824   |\n",
      "|                model_bert.encoder.layer.1.attention.self.value.bias               |    768     |\n",
      "|              model_bert.encoder.layer.1.attention.output.dense.weight             |   589824   |\n",
      "|               model_bert.encoder.layer.1.attention.output.dense.bias              |    768     |\n",
      "|            model_bert.encoder.layer.1.attention.output.LayerNorm.weight           |    768     |\n",
      "|             model_bert.encoder.layer.1.attention.output.LayerNorm.bias            |    768     |\n",
      "|                model_bert.encoder.layer.1.intermediate.dense.weight               |  2359296   |\n",
      "|                 model_bert.encoder.layer.1.intermediate.dense.bias                |    3072    |\n",
      "|                   model_bert.encoder.layer.1.output.dense.weight                  |  2359296   |\n",
      "|                    model_bert.encoder.layer.1.output.dense.bias                   |    768     |\n",
      "|                 model_bert.encoder.layer.1.output.LayerNorm.weight                |    768     |\n",
      "|                  model_bert.encoder.layer.1.output.LayerNorm.bias                 |    768     |\n",
      "|               model_bert.encoder.layer.2.attention.self.query.weight              |   589824   |\n",
      "|                model_bert.encoder.layer.2.attention.self.query.bias               |    768     |\n",
      "|                model_bert.encoder.layer.2.attention.self.key.weight               |   589824   |\n",
      "|                 model_bert.encoder.layer.2.attention.self.key.bias                |    768     |\n",
      "|               model_bert.encoder.layer.2.attention.self.value.weight              |   589824   |\n",
      "|                model_bert.encoder.layer.2.attention.self.value.bias               |    768     |\n",
      "|              model_bert.encoder.layer.2.attention.output.dense.weight             |   589824   |\n",
      "|               model_bert.encoder.layer.2.attention.output.dense.bias              |    768     |\n",
      "|            model_bert.encoder.layer.2.attention.output.LayerNorm.weight           |    768     |\n",
      "|             model_bert.encoder.layer.2.attention.output.LayerNorm.bias            |    768     |\n",
      "|                model_bert.encoder.layer.2.intermediate.dense.weight               |  2359296   |\n",
      "|                 model_bert.encoder.layer.2.intermediate.dense.bias                |    3072    |\n",
      "|                   model_bert.encoder.layer.2.output.dense.weight                  |  2359296   |\n",
      "|                    model_bert.encoder.layer.2.output.dense.bias                   |    768     |\n",
      "|                 model_bert.encoder.layer.2.output.LayerNorm.weight                |    768     |\n",
      "|                  model_bert.encoder.layer.2.output.LayerNorm.bias                 |    768     |\n",
      "|               model_bert.encoder.layer.3.attention.self.query.weight              |   589824   |\n",
      "|                model_bert.encoder.layer.3.attention.self.query.bias               |    768     |\n",
      "|                model_bert.encoder.layer.3.attention.self.key.weight               |   589824   |\n",
      "|                 model_bert.encoder.layer.3.attention.self.key.bias                |    768     |\n",
      "|               model_bert.encoder.layer.3.attention.self.value.weight              |   589824   |\n",
      "|                model_bert.encoder.layer.3.attention.self.value.bias               |    768     |\n",
      "|              model_bert.encoder.layer.3.attention.output.dense.weight             |   589824   |\n",
      "|               model_bert.encoder.layer.3.attention.output.dense.bias              |    768     |\n",
      "|            model_bert.encoder.layer.3.attention.output.LayerNorm.weight           |    768     |\n",
      "|             model_bert.encoder.layer.3.attention.output.LayerNorm.bias            |    768     |\n",
      "|                model_bert.encoder.layer.3.intermediate.dense.weight               |  2359296   |\n",
      "|                 model_bert.encoder.layer.3.intermediate.dense.bias                |    3072    |\n",
      "|                   model_bert.encoder.layer.3.output.dense.weight                  |  2359296   |\n",
      "|                    model_bert.encoder.layer.3.output.dense.bias                   |    768     |\n",
      "|                 model_bert.encoder.layer.3.output.LayerNorm.weight                |    768     |\n",
      "|                  model_bert.encoder.layer.3.output.LayerNorm.bias                 |    768     |\n",
      "|               model_bert.encoder.layer.4.attention.self.query.weight              |   589824   |\n",
      "|                model_bert.encoder.layer.4.attention.self.query.bias               |    768     |\n",
      "|                model_bert.encoder.layer.4.attention.self.key.weight               |   589824   |\n",
      "|                 model_bert.encoder.layer.4.attention.self.key.bias                |    768     |\n",
      "|               model_bert.encoder.layer.4.attention.self.value.weight              |   589824   |\n",
      "|                model_bert.encoder.layer.4.attention.self.value.bias               |    768     |\n",
      "|              model_bert.encoder.layer.4.attention.output.dense.weight             |   589824   |\n",
      "|               model_bert.encoder.layer.4.attention.output.dense.bias              |    768     |\n",
      "|            model_bert.encoder.layer.4.attention.output.LayerNorm.weight           |    768     |\n",
      "|             model_bert.encoder.layer.4.attention.output.LayerNorm.bias            |    768     |\n",
      "|                model_bert.encoder.layer.4.intermediate.dense.weight               |  2359296   |\n",
      "|                 model_bert.encoder.layer.4.intermediate.dense.bias                |    3072    |\n",
      "|                   model_bert.encoder.layer.4.output.dense.weight                  |  2359296   |\n",
      "|                    model_bert.encoder.layer.4.output.dense.bias                   |    768     |\n",
      "|                 model_bert.encoder.layer.4.output.LayerNorm.weight                |    768     |\n",
      "|                  model_bert.encoder.layer.4.output.LayerNorm.bias                 |    768     |\n",
      "|               model_bert.encoder.layer.5.attention.self.query.weight              |   589824   |\n",
      "|                model_bert.encoder.layer.5.attention.self.query.bias               |    768     |\n",
      "|                model_bert.encoder.layer.5.attention.self.key.weight               |   589824   |\n",
      "|                 model_bert.encoder.layer.5.attention.self.key.bias                |    768     |\n",
      "|               model_bert.encoder.layer.5.attention.self.value.weight              |   589824   |\n",
      "|                model_bert.encoder.layer.5.attention.self.value.bias               |    768     |\n",
      "|              model_bert.encoder.layer.5.attention.output.dense.weight             |   589824   |\n",
      "|               model_bert.encoder.layer.5.attention.output.dense.bias              |    768     |\n",
      "|            model_bert.encoder.layer.5.attention.output.LayerNorm.weight           |    768     |\n",
      "|             model_bert.encoder.layer.5.attention.output.LayerNorm.bias            |    768     |\n",
      "|                model_bert.encoder.layer.5.intermediate.dense.weight               |  2359296   |\n",
      "|                 model_bert.encoder.layer.5.intermediate.dense.bias                |    3072    |\n",
      "|                   model_bert.encoder.layer.5.output.dense.weight                  |  2359296   |\n",
      "|                    model_bert.encoder.layer.5.output.dense.bias                   |    768     |\n",
      "|                 model_bert.encoder.layer.5.output.LayerNorm.weight                |    768     |\n",
      "|                  model_bert.encoder.layer.5.output.LayerNorm.bias                 |    768     |\n",
      "|               model_bert.encoder.layer.6.attention.self.query.weight              |   589824   |\n",
      "|                model_bert.encoder.layer.6.attention.self.query.bias               |    768     |\n",
      "|                model_bert.encoder.layer.6.attention.self.key.weight               |   589824   |\n",
      "|                 model_bert.encoder.layer.6.attention.self.key.bias                |    768     |\n",
      "|               model_bert.encoder.layer.6.attention.self.value.weight              |   589824   |\n",
      "|                model_bert.encoder.layer.6.attention.self.value.bias               |    768     |\n",
      "|              model_bert.encoder.layer.6.attention.output.dense.weight             |   589824   |\n",
      "|               model_bert.encoder.layer.6.attention.output.dense.bias              |    768     |\n",
      "|            model_bert.encoder.layer.6.attention.output.LayerNorm.weight           |    768     |\n",
      "|             model_bert.encoder.layer.6.attention.output.LayerNorm.bias            |    768     |\n",
      "|                model_bert.encoder.layer.6.intermediate.dense.weight               |  2359296   |\n",
      "|                 model_bert.encoder.layer.6.intermediate.dense.bias                |    3072    |\n",
      "|                   model_bert.encoder.layer.6.output.dense.weight                  |  2359296   |\n",
      "|                    model_bert.encoder.layer.6.output.dense.bias                   |    768     |\n",
      "|                 model_bert.encoder.layer.6.output.LayerNorm.weight                |    768     |\n",
      "|                  model_bert.encoder.layer.6.output.LayerNorm.bias                 |    768     |\n",
      "|               model_bert.encoder.layer.7.attention.self.query.weight              |   589824   |\n",
      "|                model_bert.encoder.layer.7.attention.self.query.bias               |    768     |\n",
      "|                model_bert.encoder.layer.7.attention.self.key.weight               |   589824   |\n",
      "|                 model_bert.encoder.layer.7.attention.self.key.bias                |    768     |\n",
      "|               model_bert.encoder.layer.7.attention.self.value.weight              |   589824   |\n",
      "|                model_bert.encoder.layer.7.attention.self.value.bias               |    768     |\n",
      "|              model_bert.encoder.layer.7.attention.output.dense.weight             |   589824   |\n",
      "|               model_bert.encoder.layer.7.attention.output.dense.bias              |    768     |\n",
      "|            model_bert.encoder.layer.7.attention.output.LayerNorm.weight           |    768     |\n",
      "|             model_bert.encoder.layer.7.attention.output.LayerNorm.bias            |    768     |\n",
      "|                model_bert.encoder.layer.7.intermediate.dense.weight               |  2359296   |\n",
      "|                 model_bert.encoder.layer.7.intermediate.dense.bias                |    3072    |\n",
      "|                   model_bert.encoder.layer.7.output.dense.weight                  |  2359296   |\n",
      "|                    model_bert.encoder.layer.7.output.dense.bias                   |    768     |\n",
      "|                 model_bert.encoder.layer.7.output.LayerNorm.weight                |    768     |\n",
      "|                  model_bert.encoder.layer.7.output.LayerNorm.bias                 |    768     |\n",
      "|               model_bert.encoder.layer.8.attention.self.query.weight              |   589824   |\n",
      "|                model_bert.encoder.layer.8.attention.self.query.bias               |    768     |\n",
      "|                model_bert.encoder.layer.8.attention.self.key.weight               |   589824   |\n",
      "|                 model_bert.encoder.layer.8.attention.self.key.bias                |    768     |\n",
      "|               model_bert.encoder.layer.8.attention.self.value.weight              |   589824   |\n",
      "|                model_bert.encoder.layer.8.attention.self.value.bias               |    768     |\n",
      "|              model_bert.encoder.layer.8.attention.output.dense.weight             |   589824   |\n",
      "|               model_bert.encoder.layer.8.attention.output.dense.bias              |    768     |\n",
      "|            model_bert.encoder.layer.8.attention.output.LayerNorm.weight           |    768     |\n",
      "|             model_bert.encoder.layer.8.attention.output.LayerNorm.bias            |    768     |\n",
      "|                model_bert.encoder.layer.8.intermediate.dense.weight               |  2359296   |\n",
      "|                 model_bert.encoder.layer.8.intermediate.dense.bias                |    3072    |\n",
      "|                   model_bert.encoder.layer.8.output.dense.weight                  |  2359296   |\n",
      "|                    model_bert.encoder.layer.8.output.dense.bias                   |    768     |\n",
      "|                 model_bert.encoder.layer.8.output.LayerNorm.weight                |    768     |\n",
      "|                  model_bert.encoder.layer.8.output.LayerNorm.bias                 |    768     |\n",
      "|               model_bert.encoder.layer.9.attention.self.query.weight              |   589824   |\n",
      "|                model_bert.encoder.layer.9.attention.self.query.bias               |    768     |\n",
      "|                model_bert.encoder.layer.9.attention.self.key.weight               |   589824   |\n",
      "|                 model_bert.encoder.layer.9.attention.self.key.bias                |    768     |\n",
      "|               model_bert.encoder.layer.9.attention.self.value.weight              |   589824   |\n",
      "|                model_bert.encoder.layer.9.attention.self.value.bias               |    768     |\n",
      "|              model_bert.encoder.layer.9.attention.output.dense.weight             |   589824   |\n",
      "|               model_bert.encoder.layer.9.attention.output.dense.bias              |    768     |\n",
      "|            model_bert.encoder.layer.9.attention.output.LayerNorm.weight           |    768     |\n",
      "|             model_bert.encoder.layer.9.attention.output.LayerNorm.bias            |    768     |\n",
      "|                model_bert.encoder.layer.9.intermediate.dense.weight               |  2359296   |\n",
      "|                 model_bert.encoder.layer.9.intermediate.dense.bias                |    3072    |\n",
      "|                   model_bert.encoder.layer.9.output.dense.weight                  |  2359296   |\n",
      "|                    model_bert.encoder.layer.9.output.dense.bias                   |    768     |\n",
      "|                 model_bert.encoder.layer.9.output.LayerNorm.weight                |    768     |\n",
      "|                  model_bert.encoder.layer.9.output.LayerNorm.bias                 |    768     |\n",
      "|              model_bert.encoder.layer.10.attention.self.query.weight              |   589824   |\n",
      "|               model_bert.encoder.layer.10.attention.self.query.bias               |    768     |\n",
      "|               model_bert.encoder.layer.10.attention.self.key.weight               |   589824   |\n",
      "|                model_bert.encoder.layer.10.attention.self.key.bias                |    768     |\n",
      "|              model_bert.encoder.layer.10.attention.self.value.weight              |   589824   |\n",
      "|               model_bert.encoder.layer.10.attention.self.value.bias               |    768     |\n",
      "|             model_bert.encoder.layer.10.attention.output.dense.weight             |   589824   |\n",
      "|              model_bert.encoder.layer.10.attention.output.dense.bias              |    768     |\n",
      "|           model_bert.encoder.layer.10.attention.output.LayerNorm.weight           |    768     |\n",
      "|            model_bert.encoder.layer.10.attention.output.LayerNorm.bias            |    768     |\n",
      "|               model_bert.encoder.layer.10.intermediate.dense.weight               |  2359296   |\n",
      "|                model_bert.encoder.layer.10.intermediate.dense.bias                |    3072    |\n",
      "|                  model_bert.encoder.layer.10.output.dense.weight                  |  2359296   |\n",
      "|                   model_bert.encoder.layer.10.output.dense.bias                   |    768     |\n",
      "|                model_bert.encoder.layer.10.output.LayerNorm.weight                |    768     |\n",
      "|                 model_bert.encoder.layer.10.output.LayerNorm.bias                 |    768     |\n",
      "|              model_bert.encoder.layer.11.attention.self.query.weight              |   589824   |\n",
      "|               model_bert.encoder.layer.11.attention.self.query.bias               |    768     |\n",
      "|               model_bert.encoder.layer.11.attention.self.key.weight               |   589824   |\n",
      "|                model_bert.encoder.layer.11.attention.self.key.bias                |    768     |\n",
      "|              model_bert.encoder.layer.11.attention.self.value.weight              |   589824   |\n",
      "|               model_bert.encoder.layer.11.attention.self.value.bias               |    768     |\n",
      "|             model_bert.encoder.layer.11.attention.output.dense.weight             |   589824   |\n",
      "|              model_bert.encoder.layer.11.attention.output.dense.bias              |    768     |\n",
      "|           model_bert.encoder.layer.11.attention.output.LayerNorm.weight           |    768     |\n",
      "|            model_bert.encoder.layer.11.attention.output.LayerNorm.bias            |    768     |\n",
      "|               model_bert.encoder.layer.11.intermediate.dense.weight               |  2359296   |\n",
      "|                model_bert.encoder.layer.11.intermediate.dense.bias                |    3072    |\n",
      "|                  model_bert.encoder.layer.11.output.dense.weight                  |  2359296   |\n",
      "|                   model_bert.encoder.layer.11.output.dense.bias                   |    768     |\n",
      "|                model_bert.encoder.layer.11.output.LayerNorm.weight                |    768     |\n",
      "|                 model_bert.encoder.layer.11.output.LayerNorm.bias                 |    768     |\n",
      "|                           model_bert.pooler.dense.weight                          |   589824   |\n",
      "|                            model_bert.pooler.dense.bias                           |    768     |\n",
      "|                     model_encdec.encoder.embeddings.cls_token                     |    768     |\n",
      "|                     model_encdec.encoder.embeddings.mask_token                    |    768     |\n",
      "|         model_encdec.encoder.embeddings.patch_embeddings.projection.weight        |   589824   |\n",
      "|          model_encdec.encoder.embeddings.patch_embeddings.projection.bias         |    768     |\n",
      "|  model_encdec.encoder.encoder.relative_position_bias.relative_position_bias_table |    8784    |\n",
      "|                   model_encdec.encoder.encoder.layer.0.lambda_1                   |    768     |\n",
      "|                   model_encdec.encoder.encoder.layer.0.lambda_2                   |    768     |\n",
      "|       model_encdec.encoder.encoder.layer.0.attention.attention.query.weight       |   589824   |\n",
      "|        model_encdec.encoder.encoder.layer.0.attention.attention.query.bias        |    768     |\n",
      "|        model_encdec.encoder.encoder.layer.0.attention.attention.key.weight        |   589824   |\n",
      "|       model_encdec.encoder.encoder.layer.0.attention.attention.value.weight       |   589824   |\n",
      "|        model_encdec.encoder.encoder.layer.0.attention.attention.value.bias        |    768     |\n",
      "|         model_encdec.encoder.encoder.layer.0.attention.output.dense.weight        |   589824   |\n",
      "|          model_encdec.encoder.encoder.layer.0.attention.output.dense.bias         |    768     |\n",
      "|           model_encdec.encoder.encoder.layer.0.intermediate.dense.weight          |  2359296   |\n",
      "|            model_encdec.encoder.encoder.layer.0.intermediate.dense.bias           |    3072    |\n",
      "|              model_encdec.encoder.encoder.layer.0.output.dense.weight             |  2359296   |\n",
      "|               model_encdec.encoder.encoder.layer.0.output.dense.bias              |    768     |\n",
      "|            model_encdec.encoder.encoder.layer.0.layernorm_before.weight           |    768     |\n",
      "|             model_encdec.encoder.encoder.layer.0.layernorm_before.bias            |    768     |\n",
      "|            model_encdec.encoder.encoder.layer.0.layernorm_after.weight            |    768     |\n",
      "|             model_encdec.encoder.encoder.layer.0.layernorm_after.bias             |    768     |\n",
      "|                   model_encdec.encoder.encoder.layer.1.lambda_1                   |    768     |\n",
      "|                   model_encdec.encoder.encoder.layer.1.lambda_2                   |    768     |\n",
      "|       model_encdec.encoder.encoder.layer.1.attention.attention.query.weight       |   589824   |\n",
      "|        model_encdec.encoder.encoder.layer.1.attention.attention.query.bias        |    768     |\n",
      "|        model_encdec.encoder.encoder.layer.1.attention.attention.key.weight        |   589824   |\n",
      "|       model_encdec.encoder.encoder.layer.1.attention.attention.value.weight       |   589824   |\n",
      "|        model_encdec.encoder.encoder.layer.1.attention.attention.value.bias        |    768     |\n",
      "|         model_encdec.encoder.encoder.layer.1.attention.output.dense.weight        |   589824   |\n",
      "|          model_encdec.encoder.encoder.layer.1.attention.output.dense.bias         |    768     |\n",
      "|           model_encdec.encoder.encoder.layer.1.intermediate.dense.weight          |  2359296   |\n",
      "|            model_encdec.encoder.encoder.layer.1.intermediate.dense.bias           |    3072    |\n",
      "|              model_encdec.encoder.encoder.layer.1.output.dense.weight             |  2359296   |\n",
      "|               model_encdec.encoder.encoder.layer.1.output.dense.bias              |    768     |\n",
      "|            model_encdec.encoder.encoder.layer.1.layernorm_before.weight           |    768     |\n",
      "|             model_encdec.encoder.encoder.layer.1.layernorm_before.bias            |    768     |\n",
      "|            model_encdec.encoder.encoder.layer.1.layernorm_after.weight            |    768     |\n",
      "|             model_encdec.encoder.encoder.layer.1.layernorm_after.bias             |    768     |\n",
      "|                   model_encdec.encoder.encoder.layer.2.lambda_1                   |    768     |\n",
      "|                   model_encdec.encoder.encoder.layer.2.lambda_2                   |    768     |\n",
      "|       model_encdec.encoder.encoder.layer.2.attention.attention.query.weight       |   589824   |\n",
      "|        model_encdec.encoder.encoder.layer.2.attention.attention.query.bias        |    768     |\n",
      "|        model_encdec.encoder.encoder.layer.2.attention.attention.key.weight        |   589824   |\n",
      "|       model_encdec.encoder.encoder.layer.2.attention.attention.value.weight       |   589824   |\n",
      "|        model_encdec.encoder.encoder.layer.2.attention.attention.value.bias        |    768     |\n",
      "|         model_encdec.encoder.encoder.layer.2.attention.output.dense.weight        |   589824   |\n",
      "|          model_encdec.encoder.encoder.layer.2.attention.output.dense.bias         |    768     |\n",
      "|           model_encdec.encoder.encoder.layer.2.intermediate.dense.weight          |  2359296   |\n",
      "|            model_encdec.encoder.encoder.layer.2.intermediate.dense.bias           |    3072    |\n",
      "|              model_encdec.encoder.encoder.layer.2.output.dense.weight             |  2359296   |\n",
      "|               model_encdec.encoder.encoder.layer.2.output.dense.bias              |    768     |\n",
      "|            model_encdec.encoder.encoder.layer.2.layernorm_before.weight           |    768     |\n",
      "|             model_encdec.encoder.encoder.layer.2.layernorm_before.bias            |    768     |\n",
      "|            model_encdec.encoder.encoder.layer.2.layernorm_after.weight            |    768     |\n",
      "|             model_encdec.encoder.encoder.layer.2.layernorm_after.bias             |    768     |\n",
      "|                   model_encdec.encoder.encoder.layer.3.lambda_1                   |    768     |\n",
      "|                   model_encdec.encoder.encoder.layer.3.lambda_2                   |    768     |\n",
      "|       model_encdec.encoder.encoder.layer.3.attention.attention.query.weight       |   589824   |\n",
      "|        model_encdec.encoder.encoder.layer.3.attention.attention.query.bias        |    768     |\n",
      "|        model_encdec.encoder.encoder.layer.3.attention.attention.key.weight        |   589824   |\n",
      "|       model_encdec.encoder.encoder.layer.3.attention.attention.value.weight       |   589824   |\n",
      "|        model_encdec.encoder.encoder.layer.3.attention.attention.value.bias        |    768     |\n",
      "|         model_encdec.encoder.encoder.layer.3.attention.output.dense.weight        |   589824   |\n",
      "|          model_encdec.encoder.encoder.layer.3.attention.output.dense.bias         |    768     |\n",
      "|           model_encdec.encoder.encoder.layer.3.intermediate.dense.weight          |  2359296   |\n",
      "|            model_encdec.encoder.encoder.layer.3.intermediate.dense.bias           |    3072    |\n",
      "|              model_encdec.encoder.encoder.layer.3.output.dense.weight             |  2359296   |\n",
      "|               model_encdec.encoder.encoder.layer.3.output.dense.bias              |    768     |\n",
      "|            model_encdec.encoder.encoder.layer.3.layernorm_before.weight           |    768     |\n",
      "|             model_encdec.encoder.encoder.layer.3.layernorm_before.bias            |    768     |\n",
      "|            model_encdec.encoder.encoder.layer.3.layernorm_after.weight            |    768     |\n",
      "|             model_encdec.encoder.encoder.layer.3.layernorm_after.bias             |    768     |\n",
      "|                   model_encdec.encoder.encoder.layer.4.lambda_1                   |    768     |\n",
      "|                   model_encdec.encoder.encoder.layer.4.lambda_2                   |    768     |\n",
      "|       model_encdec.encoder.encoder.layer.4.attention.attention.query.weight       |   589824   |\n",
      "|        model_encdec.encoder.encoder.layer.4.attention.attention.query.bias        |    768     |\n",
      "|        model_encdec.encoder.encoder.layer.4.attention.attention.key.weight        |   589824   |\n",
      "|       model_encdec.encoder.encoder.layer.4.attention.attention.value.weight       |   589824   |\n",
      "|        model_encdec.encoder.encoder.layer.4.attention.attention.value.bias        |    768     |\n",
      "|         model_encdec.encoder.encoder.layer.4.attention.output.dense.weight        |   589824   |\n",
      "|          model_encdec.encoder.encoder.layer.4.attention.output.dense.bias         |    768     |\n",
      "|           model_encdec.encoder.encoder.layer.4.intermediate.dense.weight          |  2359296   |\n",
      "|            model_encdec.encoder.encoder.layer.4.intermediate.dense.bias           |    3072    |\n",
      "|              model_encdec.encoder.encoder.layer.4.output.dense.weight             |  2359296   |\n",
      "|               model_encdec.encoder.encoder.layer.4.output.dense.bias              |    768     |\n",
      "|            model_encdec.encoder.encoder.layer.4.layernorm_before.weight           |    768     |\n",
      "|             model_encdec.encoder.encoder.layer.4.layernorm_before.bias            |    768     |\n",
      "|            model_encdec.encoder.encoder.layer.4.layernorm_after.weight            |    768     |\n",
      "|             model_encdec.encoder.encoder.layer.4.layernorm_after.bias             |    768     |\n",
      "|                   model_encdec.encoder.encoder.layer.5.lambda_1                   |    768     |\n",
      "|                   model_encdec.encoder.encoder.layer.5.lambda_2                   |    768     |\n",
      "|       model_encdec.encoder.encoder.layer.5.attention.attention.query.weight       |   589824   |\n",
      "|        model_encdec.encoder.encoder.layer.5.attention.attention.query.bias        |    768     |\n",
      "|        model_encdec.encoder.encoder.layer.5.attention.attention.key.weight        |   589824   |\n",
      "|       model_encdec.encoder.encoder.layer.5.attention.attention.value.weight       |   589824   |\n",
      "|        model_encdec.encoder.encoder.layer.5.attention.attention.value.bias        |    768     |\n",
      "|         model_encdec.encoder.encoder.layer.5.attention.output.dense.weight        |   589824   |\n",
      "|          model_encdec.encoder.encoder.layer.5.attention.output.dense.bias         |    768     |\n",
      "|           model_encdec.encoder.encoder.layer.5.intermediate.dense.weight          |  2359296   |\n",
      "|            model_encdec.encoder.encoder.layer.5.intermediate.dense.bias           |    3072    |\n",
      "|              model_encdec.encoder.encoder.layer.5.output.dense.weight             |  2359296   |\n",
      "|               model_encdec.encoder.encoder.layer.5.output.dense.bias              |    768     |\n",
      "|            model_encdec.encoder.encoder.layer.5.layernorm_before.weight           |    768     |\n",
      "|             model_encdec.encoder.encoder.layer.5.layernorm_before.bias            |    768     |\n",
      "|            model_encdec.encoder.encoder.layer.5.layernorm_after.weight            |    768     |\n",
      "|             model_encdec.encoder.encoder.layer.5.layernorm_after.bias             |    768     |\n",
      "|                   model_encdec.encoder.encoder.layer.6.lambda_1                   |    768     |\n",
      "|                   model_encdec.encoder.encoder.layer.6.lambda_2                   |    768     |\n",
      "|       model_encdec.encoder.encoder.layer.6.attention.attention.query.weight       |   589824   |\n",
      "|        model_encdec.encoder.encoder.layer.6.attention.attention.query.bias        |    768     |\n",
      "|        model_encdec.encoder.encoder.layer.6.attention.attention.key.weight        |   589824   |\n",
      "|       model_encdec.encoder.encoder.layer.6.attention.attention.value.weight       |   589824   |\n",
      "|        model_encdec.encoder.encoder.layer.6.attention.attention.value.bias        |    768     |\n",
      "|         model_encdec.encoder.encoder.layer.6.attention.output.dense.weight        |   589824   |\n",
      "|          model_encdec.encoder.encoder.layer.6.attention.output.dense.bias         |    768     |\n",
      "|           model_encdec.encoder.encoder.layer.6.intermediate.dense.weight          |  2359296   |\n",
      "|            model_encdec.encoder.encoder.layer.6.intermediate.dense.bias           |    3072    |\n",
      "|              model_encdec.encoder.encoder.layer.6.output.dense.weight             |  2359296   |\n",
      "|               model_encdec.encoder.encoder.layer.6.output.dense.bias              |    768     |\n",
      "|            model_encdec.encoder.encoder.layer.6.layernorm_before.weight           |    768     |\n",
      "|             model_encdec.encoder.encoder.layer.6.layernorm_before.bias            |    768     |\n",
      "|            model_encdec.encoder.encoder.layer.6.layernorm_after.weight            |    768     |\n",
      "|             model_encdec.encoder.encoder.layer.6.layernorm_after.bias             |    768     |\n",
      "|                   model_encdec.encoder.encoder.layer.7.lambda_1                   |    768     |\n",
      "|                   model_encdec.encoder.encoder.layer.7.lambda_2                   |    768     |\n",
      "|       model_encdec.encoder.encoder.layer.7.attention.attention.query.weight       |   589824   |\n",
      "|        model_encdec.encoder.encoder.layer.7.attention.attention.query.bias        |    768     |\n",
      "|        model_encdec.encoder.encoder.layer.7.attention.attention.key.weight        |   589824   |\n",
      "|       model_encdec.encoder.encoder.layer.7.attention.attention.value.weight       |   589824   |\n",
      "|        model_encdec.encoder.encoder.layer.7.attention.attention.value.bias        |    768     |\n",
      "|         model_encdec.encoder.encoder.layer.7.attention.output.dense.weight        |   589824   |\n",
      "|          model_encdec.encoder.encoder.layer.7.attention.output.dense.bias         |    768     |\n",
      "|           model_encdec.encoder.encoder.layer.7.intermediate.dense.weight          |  2359296   |\n",
      "|            model_encdec.encoder.encoder.layer.7.intermediate.dense.bias           |    3072    |\n",
      "|              model_encdec.encoder.encoder.layer.7.output.dense.weight             |  2359296   |\n",
      "|               model_encdec.encoder.encoder.layer.7.output.dense.bias              |    768     |\n",
      "|            model_encdec.encoder.encoder.layer.7.layernorm_before.weight           |    768     |\n",
      "|             model_encdec.encoder.encoder.layer.7.layernorm_before.bias            |    768     |\n",
      "|            model_encdec.encoder.encoder.layer.7.layernorm_after.weight            |    768     |\n",
      "|             model_encdec.encoder.encoder.layer.7.layernorm_after.bias             |    768     |\n",
      "|                   model_encdec.encoder.encoder.layer.8.lambda_1                   |    768     |\n",
      "|                   model_encdec.encoder.encoder.layer.8.lambda_2                   |    768     |\n",
      "|       model_encdec.encoder.encoder.layer.8.attention.attention.query.weight       |   589824   |\n",
      "|        model_encdec.encoder.encoder.layer.8.attention.attention.query.bias        |    768     |\n",
      "|        model_encdec.encoder.encoder.layer.8.attention.attention.key.weight        |   589824   |\n",
      "|       model_encdec.encoder.encoder.layer.8.attention.attention.value.weight       |   589824   |\n",
      "|        model_encdec.encoder.encoder.layer.8.attention.attention.value.bias        |    768     |\n",
      "|         model_encdec.encoder.encoder.layer.8.attention.output.dense.weight        |   589824   |\n",
      "|          model_encdec.encoder.encoder.layer.8.attention.output.dense.bias         |    768     |\n",
      "|           model_encdec.encoder.encoder.layer.8.intermediate.dense.weight          |  2359296   |\n",
      "|            model_encdec.encoder.encoder.layer.8.intermediate.dense.bias           |    3072    |\n",
      "|              model_encdec.encoder.encoder.layer.8.output.dense.weight             |  2359296   |\n",
      "|               model_encdec.encoder.encoder.layer.8.output.dense.bias              |    768     |\n",
      "|            model_encdec.encoder.encoder.layer.8.layernorm_before.weight           |    768     |\n",
      "|             model_encdec.encoder.encoder.layer.8.layernorm_before.bias            |    768     |\n",
      "|            model_encdec.encoder.encoder.layer.8.layernorm_after.weight            |    768     |\n",
      "|             model_encdec.encoder.encoder.layer.8.layernorm_after.bias             |    768     |\n",
      "|                   model_encdec.encoder.encoder.layer.9.lambda_1                   |    768     |\n",
      "|                   model_encdec.encoder.encoder.layer.9.lambda_2                   |    768     |\n",
      "|       model_encdec.encoder.encoder.layer.9.attention.attention.query.weight       |   589824   |\n",
      "|        model_encdec.encoder.encoder.layer.9.attention.attention.query.bias        |    768     |\n",
      "|        model_encdec.encoder.encoder.layer.9.attention.attention.key.weight        |   589824   |\n",
      "|       model_encdec.encoder.encoder.layer.9.attention.attention.value.weight       |   589824   |\n",
      "|        model_encdec.encoder.encoder.layer.9.attention.attention.value.bias        |    768     |\n",
      "|         model_encdec.encoder.encoder.layer.9.attention.output.dense.weight        |   589824   |\n",
      "|          model_encdec.encoder.encoder.layer.9.attention.output.dense.bias         |    768     |\n",
      "|           model_encdec.encoder.encoder.layer.9.intermediate.dense.weight          |  2359296   |\n",
      "|            model_encdec.encoder.encoder.layer.9.intermediate.dense.bias           |    3072    |\n",
      "|              model_encdec.encoder.encoder.layer.9.output.dense.weight             |  2359296   |\n",
      "|               model_encdec.encoder.encoder.layer.9.output.dense.bias              |    768     |\n",
      "|            model_encdec.encoder.encoder.layer.9.layernorm_before.weight           |    768     |\n",
      "|             model_encdec.encoder.encoder.layer.9.layernorm_before.bias            |    768     |\n",
      "|            model_encdec.encoder.encoder.layer.9.layernorm_after.weight            |    768     |\n",
      "|             model_encdec.encoder.encoder.layer.9.layernorm_after.bias             |    768     |\n",
      "|                   model_encdec.encoder.encoder.layer.10.lambda_1                  |    768     |\n",
      "|                   model_encdec.encoder.encoder.layer.10.lambda_2                  |    768     |\n",
      "|       model_encdec.encoder.encoder.layer.10.attention.attention.query.weight      |   589824   |\n",
      "|        model_encdec.encoder.encoder.layer.10.attention.attention.query.bias       |    768     |\n",
      "|        model_encdec.encoder.encoder.layer.10.attention.attention.key.weight       |   589824   |\n",
      "|       model_encdec.encoder.encoder.layer.10.attention.attention.value.weight      |   589824   |\n",
      "|        model_encdec.encoder.encoder.layer.10.attention.attention.value.bias       |    768     |\n",
      "|        model_encdec.encoder.encoder.layer.10.attention.output.dense.weight        |   589824   |\n",
      "|         model_encdec.encoder.encoder.layer.10.attention.output.dense.bias         |    768     |\n",
      "|          model_encdec.encoder.encoder.layer.10.intermediate.dense.weight          |  2359296   |\n",
      "|           model_encdec.encoder.encoder.layer.10.intermediate.dense.bias           |    3072    |\n",
      "|             model_encdec.encoder.encoder.layer.10.output.dense.weight             |  2359296   |\n",
      "|              model_encdec.encoder.encoder.layer.10.output.dense.bias              |    768     |\n",
      "|           model_encdec.encoder.encoder.layer.10.layernorm_before.weight           |    768     |\n",
      "|            model_encdec.encoder.encoder.layer.10.layernorm_before.bias            |    768     |\n",
      "|            model_encdec.encoder.encoder.layer.10.layernorm_after.weight           |    768     |\n",
      "|             model_encdec.encoder.encoder.layer.10.layernorm_after.bias            |    768     |\n",
      "|                   model_encdec.encoder.encoder.layer.11.lambda_1                  |    768     |\n",
      "|                   model_encdec.encoder.encoder.layer.11.lambda_2                  |    768     |\n",
      "|       model_encdec.encoder.encoder.layer.11.attention.attention.query.weight      |   589824   |\n",
      "|        model_encdec.encoder.encoder.layer.11.attention.attention.query.bias       |    768     |\n",
      "|        model_encdec.encoder.encoder.layer.11.attention.attention.key.weight       |   589824   |\n",
      "|       model_encdec.encoder.encoder.layer.11.attention.attention.value.weight      |   589824   |\n",
      "|        model_encdec.encoder.encoder.layer.11.attention.attention.value.bias       |    768     |\n",
      "|        model_encdec.encoder.encoder.layer.11.attention.output.dense.weight        |   589824   |\n",
      "|         model_encdec.encoder.encoder.layer.11.attention.output.dense.bias         |    768     |\n",
      "|          model_encdec.encoder.encoder.layer.11.intermediate.dense.weight          |  2359296   |\n",
      "|           model_encdec.encoder.encoder.layer.11.intermediate.dense.bias           |    3072    |\n",
      "|             model_encdec.encoder.encoder.layer.11.output.dense.weight             |  2359296   |\n",
      "|              model_encdec.encoder.encoder.layer.11.output.dense.bias              |    768     |\n",
      "|           model_encdec.encoder.encoder.layer.11.layernorm_before.weight           |    768     |\n",
      "|            model_encdec.encoder.encoder.layer.11.layernorm_before.bias            |    768     |\n",
      "|            model_encdec.encoder.encoder.layer.11.layernorm_after.weight           |    768     |\n",
      "|             model_encdec.encoder.encoder.layer.11.layernorm_after.bias            |    768     |\n",
      "|                    model_encdec.encoder.pooler.layernorm.weight                   |    768     |\n",
      "|                     model_encdec.encoder.pooler.layernorm.bias                    |    768     |\n",
      "|            model_encdec.decoder.bert.embeddings.word_embeddings.weight            |  23440896  |\n",
      "|          model_encdec.decoder.bert.embeddings.position_embeddings.weight          |   393216   |\n",
      "|         model_encdec.decoder.bert.embeddings.token_type_embeddings.weight         |    1536    |\n",
      "|               model_encdec.decoder.bert.embeddings.LayerNorm.weight               |    768     |\n",
      "|                model_encdec.decoder.bert.embeddings.LayerNorm.bias                |    768     |\n",
      "|       model_encdec.decoder.bert.encoder.layer.0.attention.self.query.weight       |   589824   |\n",
      "|        model_encdec.decoder.bert.encoder.layer.0.attention.self.query.bias        |    768     |\n",
      "|        model_encdec.decoder.bert.encoder.layer.0.attention.self.key.weight        |   589824   |\n",
      "|         model_encdec.decoder.bert.encoder.layer.0.attention.self.key.bias         |    768     |\n",
      "|       model_encdec.decoder.bert.encoder.layer.0.attention.self.value.weight       |   589824   |\n",
      "|        model_encdec.decoder.bert.encoder.layer.0.attention.self.value.bias        |    768     |\n",
      "|      model_encdec.decoder.bert.encoder.layer.0.attention.output.dense.weight      |   589824   |\n",
      "|       model_encdec.decoder.bert.encoder.layer.0.attention.output.dense.bias       |    768     |\n",
      "|    model_encdec.decoder.bert.encoder.layer.0.attention.output.LayerNorm.weight    |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.0.attention.output.LayerNorm.bias     |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.0.crossattention.self.query.weight    |   589824   |\n",
      "|      model_encdec.decoder.bert.encoder.layer.0.crossattention.self.query.bias     |    768     |\n",
      "|      model_encdec.decoder.bert.encoder.layer.0.crossattention.self.key.weight     |   589824   |\n",
      "|       model_encdec.decoder.bert.encoder.layer.0.crossattention.self.key.bias      |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.0.crossattention.self.value.weight    |   589824   |\n",
      "|      model_encdec.decoder.bert.encoder.layer.0.crossattention.self.value.bias     |    768     |\n",
      "|    model_encdec.decoder.bert.encoder.layer.0.crossattention.output.dense.weight   |   589824   |\n",
      "|     model_encdec.decoder.bert.encoder.layer.0.crossattention.output.dense.bias    |    768     |\n",
      "|  model_encdec.decoder.bert.encoder.layer.0.crossattention.output.LayerNorm.weight |    768     |\n",
      "|   model_encdec.decoder.bert.encoder.layer.0.crossattention.output.LayerNorm.bias  |    768     |\n",
      "|        model_encdec.decoder.bert.encoder.layer.0.intermediate.dense.weight        |  2359296   |\n",
      "|         model_encdec.decoder.bert.encoder.layer.0.intermediate.dense.bias         |    3072    |\n",
      "|           model_encdec.decoder.bert.encoder.layer.0.output.dense.weight           |  2359296   |\n",
      "|            model_encdec.decoder.bert.encoder.layer.0.output.dense.bias            |    768     |\n",
      "|         model_encdec.decoder.bert.encoder.layer.0.output.LayerNorm.weight         |    768     |\n",
      "|          model_encdec.decoder.bert.encoder.layer.0.output.LayerNorm.bias          |    768     |\n",
      "|       model_encdec.decoder.bert.encoder.layer.1.attention.self.query.weight       |   589824   |\n",
      "|        model_encdec.decoder.bert.encoder.layer.1.attention.self.query.bias        |    768     |\n",
      "|        model_encdec.decoder.bert.encoder.layer.1.attention.self.key.weight        |   589824   |\n",
      "|         model_encdec.decoder.bert.encoder.layer.1.attention.self.key.bias         |    768     |\n",
      "|       model_encdec.decoder.bert.encoder.layer.1.attention.self.value.weight       |   589824   |\n",
      "|        model_encdec.decoder.bert.encoder.layer.1.attention.self.value.bias        |    768     |\n",
      "|      model_encdec.decoder.bert.encoder.layer.1.attention.output.dense.weight      |   589824   |\n",
      "|       model_encdec.decoder.bert.encoder.layer.1.attention.output.dense.bias       |    768     |\n",
      "|    model_encdec.decoder.bert.encoder.layer.1.attention.output.LayerNorm.weight    |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.1.attention.output.LayerNorm.bias     |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.1.crossattention.self.query.weight    |   589824   |\n",
      "|      model_encdec.decoder.bert.encoder.layer.1.crossattention.self.query.bias     |    768     |\n",
      "|      model_encdec.decoder.bert.encoder.layer.1.crossattention.self.key.weight     |   589824   |\n",
      "|       model_encdec.decoder.bert.encoder.layer.1.crossattention.self.key.bias      |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.1.crossattention.self.value.weight    |   589824   |\n",
      "|      model_encdec.decoder.bert.encoder.layer.1.crossattention.self.value.bias     |    768     |\n",
      "|    model_encdec.decoder.bert.encoder.layer.1.crossattention.output.dense.weight   |   589824   |\n",
      "|     model_encdec.decoder.bert.encoder.layer.1.crossattention.output.dense.bias    |    768     |\n",
      "|  model_encdec.decoder.bert.encoder.layer.1.crossattention.output.LayerNorm.weight |    768     |\n",
      "|   model_encdec.decoder.bert.encoder.layer.1.crossattention.output.LayerNorm.bias  |    768     |\n",
      "|        model_encdec.decoder.bert.encoder.layer.1.intermediate.dense.weight        |  2359296   |\n",
      "|         model_encdec.decoder.bert.encoder.layer.1.intermediate.dense.bias         |    3072    |\n",
      "|           model_encdec.decoder.bert.encoder.layer.1.output.dense.weight           |  2359296   |\n",
      "|            model_encdec.decoder.bert.encoder.layer.1.output.dense.bias            |    768     |\n",
      "|         model_encdec.decoder.bert.encoder.layer.1.output.LayerNorm.weight         |    768     |\n",
      "|          model_encdec.decoder.bert.encoder.layer.1.output.LayerNorm.bias          |    768     |\n",
      "|       model_encdec.decoder.bert.encoder.layer.2.attention.self.query.weight       |   589824   |\n",
      "|        model_encdec.decoder.bert.encoder.layer.2.attention.self.query.bias        |    768     |\n",
      "|        model_encdec.decoder.bert.encoder.layer.2.attention.self.key.weight        |   589824   |\n",
      "|         model_encdec.decoder.bert.encoder.layer.2.attention.self.key.bias         |    768     |\n",
      "|       model_encdec.decoder.bert.encoder.layer.2.attention.self.value.weight       |   589824   |\n",
      "|        model_encdec.decoder.bert.encoder.layer.2.attention.self.value.bias        |    768     |\n",
      "|      model_encdec.decoder.bert.encoder.layer.2.attention.output.dense.weight      |   589824   |\n",
      "|       model_encdec.decoder.bert.encoder.layer.2.attention.output.dense.bias       |    768     |\n",
      "|    model_encdec.decoder.bert.encoder.layer.2.attention.output.LayerNorm.weight    |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.2.attention.output.LayerNorm.bias     |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.2.crossattention.self.query.weight    |   589824   |\n",
      "|      model_encdec.decoder.bert.encoder.layer.2.crossattention.self.query.bias     |    768     |\n",
      "|      model_encdec.decoder.bert.encoder.layer.2.crossattention.self.key.weight     |   589824   |\n",
      "|       model_encdec.decoder.bert.encoder.layer.2.crossattention.self.key.bias      |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.2.crossattention.self.value.weight    |   589824   |\n",
      "|      model_encdec.decoder.bert.encoder.layer.2.crossattention.self.value.bias     |    768     |\n",
      "|    model_encdec.decoder.bert.encoder.layer.2.crossattention.output.dense.weight   |   589824   |\n",
      "|     model_encdec.decoder.bert.encoder.layer.2.crossattention.output.dense.bias    |    768     |\n",
      "|  model_encdec.decoder.bert.encoder.layer.2.crossattention.output.LayerNorm.weight |    768     |\n",
      "|   model_encdec.decoder.bert.encoder.layer.2.crossattention.output.LayerNorm.bias  |    768     |\n",
      "|        model_encdec.decoder.bert.encoder.layer.2.intermediate.dense.weight        |  2359296   |\n",
      "|         model_encdec.decoder.bert.encoder.layer.2.intermediate.dense.bias         |    3072    |\n",
      "|           model_encdec.decoder.bert.encoder.layer.2.output.dense.weight           |  2359296   |\n",
      "|            model_encdec.decoder.bert.encoder.layer.2.output.dense.bias            |    768     |\n",
      "|         model_encdec.decoder.bert.encoder.layer.2.output.LayerNorm.weight         |    768     |\n",
      "|          model_encdec.decoder.bert.encoder.layer.2.output.LayerNorm.bias          |    768     |\n",
      "|       model_encdec.decoder.bert.encoder.layer.3.attention.self.query.weight       |   589824   |\n",
      "|        model_encdec.decoder.bert.encoder.layer.3.attention.self.query.bias        |    768     |\n",
      "|        model_encdec.decoder.bert.encoder.layer.3.attention.self.key.weight        |   589824   |\n",
      "|         model_encdec.decoder.bert.encoder.layer.3.attention.self.key.bias         |    768     |\n",
      "|       model_encdec.decoder.bert.encoder.layer.3.attention.self.value.weight       |   589824   |\n",
      "|        model_encdec.decoder.bert.encoder.layer.3.attention.self.value.bias        |    768     |\n",
      "|      model_encdec.decoder.bert.encoder.layer.3.attention.output.dense.weight      |   589824   |\n",
      "|       model_encdec.decoder.bert.encoder.layer.3.attention.output.dense.bias       |    768     |\n",
      "|    model_encdec.decoder.bert.encoder.layer.3.attention.output.LayerNorm.weight    |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.3.attention.output.LayerNorm.bias     |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.3.crossattention.self.query.weight    |   589824   |\n",
      "|      model_encdec.decoder.bert.encoder.layer.3.crossattention.self.query.bias     |    768     |\n",
      "|      model_encdec.decoder.bert.encoder.layer.3.crossattention.self.key.weight     |   589824   |\n",
      "|       model_encdec.decoder.bert.encoder.layer.3.crossattention.self.key.bias      |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.3.crossattention.self.value.weight    |   589824   |\n",
      "|      model_encdec.decoder.bert.encoder.layer.3.crossattention.self.value.bias     |    768     |\n",
      "|    model_encdec.decoder.bert.encoder.layer.3.crossattention.output.dense.weight   |   589824   |\n",
      "|     model_encdec.decoder.bert.encoder.layer.3.crossattention.output.dense.bias    |    768     |\n",
      "|  model_encdec.decoder.bert.encoder.layer.3.crossattention.output.LayerNorm.weight |    768     |\n",
      "|   model_encdec.decoder.bert.encoder.layer.3.crossattention.output.LayerNorm.bias  |    768     |\n",
      "|        model_encdec.decoder.bert.encoder.layer.3.intermediate.dense.weight        |  2359296   |\n",
      "|         model_encdec.decoder.bert.encoder.layer.3.intermediate.dense.bias         |    3072    |\n",
      "|           model_encdec.decoder.bert.encoder.layer.3.output.dense.weight           |  2359296   |\n",
      "|            model_encdec.decoder.bert.encoder.layer.3.output.dense.bias            |    768     |\n",
      "|         model_encdec.decoder.bert.encoder.layer.3.output.LayerNorm.weight         |    768     |\n",
      "|          model_encdec.decoder.bert.encoder.layer.3.output.LayerNorm.bias          |    768     |\n",
      "|       model_encdec.decoder.bert.encoder.layer.4.attention.self.query.weight       |   589824   |\n",
      "|        model_encdec.decoder.bert.encoder.layer.4.attention.self.query.bias        |    768     |\n",
      "|        model_encdec.decoder.bert.encoder.layer.4.attention.self.key.weight        |   589824   |\n",
      "|         model_encdec.decoder.bert.encoder.layer.4.attention.self.key.bias         |    768     |\n",
      "|       model_encdec.decoder.bert.encoder.layer.4.attention.self.value.weight       |   589824   |\n",
      "|        model_encdec.decoder.bert.encoder.layer.4.attention.self.value.bias        |    768     |\n",
      "|      model_encdec.decoder.bert.encoder.layer.4.attention.output.dense.weight      |   589824   |\n",
      "|       model_encdec.decoder.bert.encoder.layer.4.attention.output.dense.bias       |    768     |\n",
      "|    model_encdec.decoder.bert.encoder.layer.4.attention.output.LayerNorm.weight    |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.4.attention.output.LayerNorm.bias     |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.4.crossattention.self.query.weight    |   589824   |\n",
      "|      model_encdec.decoder.bert.encoder.layer.4.crossattention.self.query.bias     |    768     |\n",
      "|      model_encdec.decoder.bert.encoder.layer.4.crossattention.self.key.weight     |   589824   |\n",
      "|       model_encdec.decoder.bert.encoder.layer.4.crossattention.self.key.bias      |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.4.crossattention.self.value.weight    |   589824   |\n",
      "|      model_encdec.decoder.bert.encoder.layer.4.crossattention.self.value.bias     |    768     |\n",
      "|    model_encdec.decoder.bert.encoder.layer.4.crossattention.output.dense.weight   |   589824   |\n",
      "|     model_encdec.decoder.bert.encoder.layer.4.crossattention.output.dense.bias    |    768     |\n",
      "|  model_encdec.decoder.bert.encoder.layer.4.crossattention.output.LayerNorm.weight |    768     |\n",
      "|   model_encdec.decoder.bert.encoder.layer.4.crossattention.output.LayerNorm.bias  |    768     |\n",
      "|        model_encdec.decoder.bert.encoder.layer.4.intermediate.dense.weight        |  2359296   |\n",
      "|         model_encdec.decoder.bert.encoder.layer.4.intermediate.dense.bias         |    3072    |\n",
      "|           model_encdec.decoder.bert.encoder.layer.4.output.dense.weight           |  2359296   |\n",
      "|            model_encdec.decoder.bert.encoder.layer.4.output.dense.bias            |    768     |\n",
      "|         model_encdec.decoder.bert.encoder.layer.4.output.LayerNorm.weight         |    768     |\n",
      "|          model_encdec.decoder.bert.encoder.layer.4.output.LayerNorm.bias          |    768     |\n",
      "|       model_encdec.decoder.bert.encoder.layer.5.attention.self.query.weight       |   589824   |\n",
      "|        model_encdec.decoder.bert.encoder.layer.5.attention.self.query.bias        |    768     |\n",
      "|        model_encdec.decoder.bert.encoder.layer.5.attention.self.key.weight        |   589824   |\n",
      "|         model_encdec.decoder.bert.encoder.layer.5.attention.self.key.bias         |    768     |\n",
      "|       model_encdec.decoder.bert.encoder.layer.5.attention.self.value.weight       |   589824   |\n",
      "|        model_encdec.decoder.bert.encoder.layer.5.attention.self.value.bias        |    768     |\n",
      "|      model_encdec.decoder.bert.encoder.layer.5.attention.output.dense.weight      |   589824   |\n",
      "|       model_encdec.decoder.bert.encoder.layer.5.attention.output.dense.bias       |    768     |\n",
      "|    model_encdec.decoder.bert.encoder.layer.5.attention.output.LayerNorm.weight    |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.5.attention.output.LayerNorm.bias     |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.5.crossattention.self.query.weight    |   589824   |\n",
      "|      model_encdec.decoder.bert.encoder.layer.5.crossattention.self.query.bias     |    768     |\n",
      "|      model_encdec.decoder.bert.encoder.layer.5.crossattention.self.key.weight     |   589824   |\n",
      "|       model_encdec.decoder.bert.encoder.layer.5.crossattention.self.key.bias      |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.5.crossattention.self.value.weight    |   589824   |\n",
      "|      model_encdec.decoder.bert.encoder.layer.5.crossattention.self.value.bias     |    768     |\n",
      "|    model_encdec.decoder.bert.encoder.layer.5.crossattention.output.dense.weight   |   589824   |\n",
      "|     model_encdec.decoder.bert.encoder.layer.5.crossattention.output.dense.bias    |    768     |\n",
      "|  model_encdec.decoder.bert.encoder.layer.5.crossattention.output.LayerNorm.weight |    768     |\n",
      "|   model_encdec.decoder.bert.encoder.layer.5.crossattention.output.LayerNorm.bias  |    768     |\n",
      "|        model_encdec.decoder.bert.encoder.layer.5.intermediate.dense.weight        |  2359296   |\n",
      "|         model_encdec.decoder.bert.encoder.layer.5.intermediate.dense.bias         |    3072    |\n",
      "|           model_encdec.decoder.bert.encoder.layer.5.output.dense.weight           |  2359296   |\n",
      "|            model_encdec.decoder.bert.encoder.layer.5.output.dense.bias            |    768     |\n",
      "|         model_encdec.decoder.bert.encoder.layer.5.output.LayerNorm.weight         |    768     |\n",
      "|          model_encdec.decoder.bert.encoder.layer.5.output.LayerNorm.bias          |    768     |\n",
      "|       model_encdec.decoder.bert.encoder.layer.6.attention.self.query.weight       |   589824   |\n",
      "|        model_encdec.decoder.bert.encoder.layer.6.attention.self.query.bias        |    768     |\n",
      "|        model_encdec.decoder.bert.encoder.layer.6.attention.self.key.weight        |   589824   |\n",
      "|         model_encdec.decoder.bert.encoder.layer.6.attention.self.key.bias         |    768     |\n",
      "|       model_encdec.decoder.bert.encoder.layer.6.attention.self.value.weight       |   589824   |\n",
      "|        model_encdec.decoder.bert.encoder.layer.6.attention.self.value.bias        |    768     |\n",
      "|      model_encdec.decoder.bert.encoder.layer.6.attention.output.dense.weight      |   589824   |\n",
      "|       model_encdec.decoder.bert.encoder.layer.6.attention.output.dense.bias       |    768     |\n",
      "|    model_encdec.decoder.bert.encoder.layer.6.attention.output.LayerNorm.weight    |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.6.attention.output.LayerNorm.bias     |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.6.crossattention.self.query.weight    |   589824   |\n",
      "|      model_encdec.decoder.bert.encoder.layer.6.crossattention.self.query.bias     |    768     |\n",
      "|      model_encdec.decoder.bert.encoder.layer.6.crossattention.self.key.weight     |   589824   |\n",
      "|       model_encdec.decoder.bert.encoder.layer.6.crossattention.self.key.bias      |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.6.crossattention.self.value.weight    |   589824   |\n",
      "|      model_encdec.decoder.bert.encoder.layer.6.crossattention.self.value.bias     |    768     |\n",
      "|    model_encdec.decoder.bert.encoder.layer.6.crossattention.output.dense.weight   |   589824   |\n",
      "|     model_encdec.decoder.bert.encoder.layer.6.crossattention.output.dense.bias    |    768     |\n",
      "|  model_encdec.decoder.bert.encoder.layer.6.crossattention.output.LayerNorm.weight |    768     |\n",
      "|   model_encdec.decoder.bert.encoder.layer.6.crossattention.output.LayerNorm.bias  |    768     |\n",
      "|        model_encdec.decoder.bert.encoder.layer.6.intermediate.dense.weight        |  2359296   |\n",
      "|         model_encdec.decoder.bert.encoder.layer.6.intermediate.dense.bias         |    3072    |\n",
      "|           model_encdec.decoder.bert.encoder.layer.6.output.dense.weight           |  2359296   |\n",
      "|            model_encdec.decoder.bert.encoder.layer.6.output.dense.bias            |    768     |\n",
      "|         model_encdec.decoder.bert.encoder.layer.6.output.LayerNorm.weight         |    768     |\n",
      "|          model_encdec.decoder.bert.encoder.layer.6.output.LayerNorm.bias          |    768     |\n",
      "|       model_encdec.decoder.bert.encoder.layer.7.attention.self.query.weight       |   589824   |\n",
      "|        model_encdec.decoder.bert.encoder.layer.7.attention.self.query.bias        |    768     |\n",
      "|        model_encdec.decoder.bert.encoder.layer.7.attention.self.key.weight        |   589824   |\n",
      "|         model_encdec.decoder.bert.encoder.layer.7.attention.self.key.bias         |    768     |\n",
      "|       model_encdec.decoder.bert.encoder.layer.7.attention.self.value.weight       |   589824   |\n",
      "|        model_encdec.decoder.bert.encoder.layer.7.attention.self.value.bias        |    768     |\n",
      "|      model_encdec.decoder.bert.encoder.layer.7.attention.output.dense.weight      |   589824   |\n",
      "|       model_encdec.decoder.bert.encoder.layer.7.attention.output.dense.bias       |    768     |\n",
      "|    model_encdec.decoder.bert.encoder.layer.7.attention.output.LayerNorm.weight    |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.7.attention.output.LayerNorm.bias     |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.7.crossattention.self.query.weight    |   589824   |\n",
      "|      model_encdec.decoder.bert.encoder.layer.7.crossattention.self.query.bias     |    768     |\n",
      "|      model_encdec.decoder.bert.encoder.layer.7.crossattention.self.key.weight     |   589824   |\n",
      "|       model_encdec.decoder.bert.encoder.layer.7.crossattention.self.key.bias      |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.7.crossattention.self.value.weight    |   589824   |\n",
      "|      model_encdec.decoder.bert.encoder.layer.7.crossattention.self.value.bias     |    768     |\n",
      "|    model_encdec.decoder.bert.encoder.layer.7.crossattention.output.dense.weight   |   589824   |\n",
      "|     model_encdec.decoder.bert.encoder.layer.7.crossattention.output.dense.bias    |    768     |\n",
      "|  model_encdec.decoder.bert.encoder.layer.7.crossattention.output.LayerNorm.weight |    768     |\n",
      "|   model_encdec.decoder.bert.encoder.layer.7.crossattention.output.LayerNorm.bias  |    768     |\n",
      "|        model_encdec.decoder.bert.encoder.layer.7.intermediate.dense.weight        |  2359296   |\n",
      "|         model_encdec.decoder.bert.encoder.layer.7.intermediate.dense.bias         |    3072    |\n",
      "|           model_encdec.decoder.bert.encoder.layer.7.output.dense.weight           |  2359296   |\n",
      "|            model_encdec.decoder.bert.encoder.layer.7.output.dense.bias            |    768     |\n",
      "|         model_encdec.decoder.bert.encoder.layer.7.output.LayerNorm.weight         |    768     |\n",
      "|          model_encdec.decoder.bert.encoder.layer.7.output.LayerNorm.bias          |    768     |\n",
      "|       model_encdec.decoder.bert.encoder.layer.8.attention.self.query.weight       |   589824   |\n",
      "|        model_encdec.decoder.bert.encoder.layer.8.attention.self.query.bias        |    768     |\n",
      "|        model_encdec.decoder.bert.encoder.layer.8.attention.self.key.weight        |   589824   |\n",
      "|         model_encdec.decoder.bert.encoder.layer.8.attention.self.key.bias         |    768     |\n",
      "|       model_encdec.decoder.bert.encoder.layer.8.attention.self.value.weight       |   589824   |\n",
      "|        model_encdec.decoder.bert.encoder.layer.8.attention.self.value.bias        |    768     |\n",
      "|      model_encdec.decoder.bert.encoder.layer.8.attention.output.dense.weight      |   589824   |\n",
      "|       model_encdec.decoder.bert.encoder.layer.8.attention.output.dense.bias       |    768     |\n",
      "|    model_encdec.decoder.bert.encoder.layer.8.attention.output.LayerNorm.weight    |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.8.attention.output.LayerNorm.bias     |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.8.crossattention.self.query.weight    |   589824   |\n",
      "|      model_encdec.decoder.bert.encoder.layer.8.crossattention.self.query.bias     |    768     |\n",
      "|      model_encdec.decoder.bert.encoder.layer.8.crossattention.self.key.weight     |   589824   |\n",
      "|       model_encdec.decoder.bert.encoder.layer.8.crossattention.self.key.bias      |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.8.crossattention.self.value.weight    |   589824   |\n",
      "|      model_encdec.decoder.bert.encoder.layer.8.crossattention.self.value.bias     |    768     |\n",
      "|    model_encdec.decoder.bert.encoder.layer.8.crossattention.output.dense.weight   |   589824   |\n",
      "|     model_encdec.decoder.bert.encoder.layer.8.crossattention.output.dense.bias    |    768     |\n",
      "|  model_encdec.decoder.bert.encoder.layer.8.crossattention.output.LayerNorm.weight |    768     |\n",
      "|   model_encdec.decoder.bert.encoder.layer.8.crossattention.output.LayerNorm.bias  |    768     |\n",
      "|        model_encdec.decoder.bert.encoder.layer.8.intermediate.dense.weight        |  2359296   |\n",
      "|         model_encdec.decoder.bert.encoder.layer.8.intermediate.dense.bias         |    3072    |\n",
      "|           model_encdec.decoder.bert.encoder.layer.8.output.dense.weight           |  2359296   |\n",
      "|            model_encdec.decoder.bert.encoder.layer.8.output.dense.bias            |    768     |\n",
      "|         model_encdec.decoder.bert.encoder.layer.8.output.LayerNorm.weight         |    768     |\n",
      "|          model_encdec.decoder.bert.encoder.layer.8.output.LayerNorm.bias          |    768     |\n",
      "|       model_encdec.decoder.bert.encoder.layer.9.attention.self.query.weight       |   589824   |\n",
      "|        model_encdec.decoder.bert.encoder.layer.9.attention.self.query.bias        |    768     |\n",
      "|        model_encdec.decoder.bert.encoder.layer.9.attention.self.key.weight        |   589824   |\n",
      "|         model_encdec.decoder.bert.encoder.layer.9.attention.self.key.bias         |    768     |\n",
      "|       model_encdec.decoder.bert.encoder.layer.9.attention.self.value.weight       |   589824   |\n",
      "|        model_encdec.decoder.bert.encoder.layer.9.attention.self.value.bias        |    768     |\n",
      "|      model_encdec.decoder.bert.encoder.layer.9.attention.output.dense.weight      |   589824   |\n",
      "|       model_encdec.decoder.bert.encoder.layer.9.attention.output.dense.bias       |    768     |\n",
      "|    model_encdec.decoder.bert.encoder.layer.9.attention.output.LayerNorm.weight    |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.9.attention.output.LayerNorm.bias     |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.9.crossattention.self.query.weight    |   589824   |\n",
      "|      model_encdec.decoder.bert.encoder.layer.9.crossattention.self.query.bias     |    768     |\n",
      "|      model_encdec.decoder.bert.encoder.layer.9.crossattention.self.key.weight     |   589824   |\n",
      "|       model_encdec.decoder.bert.encoder.layer.9.crossattention.self.key.bias      |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.9.crossattention.self.value.weight    |   589824   |\n",
      "|      model_encdec.decoder.bert.encoder.layer.9.crossattention.self.value.bias     |    768     |\n",
      "|    model_encdec.decoder.bert.encoder.layer.9.crossattention.output.dense.weight   |   589824   |\n",
      "|     model_encdec.decoder.bert.encoder.layer.9.crossattention.output.dense.bias    |    768     |\n",
      "|  model_encdec.decoder.bert.encoder.layer.9.crossattention.output.LayerNorm.weight |    768     |\n",
      "|   model_encdec.decoder.bert.encoder.layer.9.crossattention.output.LayerNorm.bias  |    768     |\n",
      "|        model_encdec.decoder.bert.encoder.layer.9.intermediate.dense.weight        |  2359296   |\n",
      "|         model_encdec.decoder.bert.encoder.layer.9.intermediate.dense.bias         |    3072    |\n",
      "|           model_encdec.decoder.bert.encoder.layer.9.output.dense.weight           |  2359296   |\n",
      "|            model_encdec.decoder.bert.encoder.layer.9.output.dense.bias            |    768     |\n",
      "|         model_encdec.decoder.bert.encoder.layer.9.output.LayerNorm.weight         |    768     |\n",
      "|          model_encdec.decoder.bert.encoder.layer.9.output.LayerNorm.bias          |    768     |\n",
      "|       model_encdec.decoder.bert.encoder.layer.10.attention.self.query.weight      |   589824   |\n",
      "|        model_encdec.decoder.bert.encoder.layer.10.attention.self.query.bias       |    768     |\n",
      "|        model_encdec.decoder.bert.encoder.layer.10.attention.self.key.weight       |   589824   |\n",
      "|         model_encdec.decoder.bert.encoder.layer.10.attention.self.key.bias        |    768     |\n",
      "|       model_encdec.decoder.bert.encoder.layer.10.attention.self.value.weight      |   589824   |\n",
      "|        model_encdec.decoder.bert.encoder.layer.10.attention.self.value.bias       |    768     |\n",
      "|      model_encdec.decoder.bert.encoder.layer.10.attention.output.dense.weight     |   589824   |\n",
      "|       model_encdec.decoder.bert.encoder.layer.10.attention.output.dense.bias      |    768     |\n",
      "|    model_encdec.decoder.bert.encoder.layer.10.attention.output.LayerNorm.weight   |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.10.attention.output.LayerNorm.bias    |    768     |\n",
      "|    model_encdec.decoder.bert.encoder.layer.10.crossattention.self.query.weight    |   589824   |\n",
      "|     model_encdec.decoder.bert.encoder.layer.10.crossattention.self.query.bias     |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.10.crossattention.self.key.weight     |   589824   |\n",
      "|      model_encdec.decoder.bert.encoder.layer.10.crossattention.self.key.bias      |    768     |\n",
      "|    model_encdec.decoder.bert.encoder.layer.10.crossattention.self.value.weight    |   589824   |\n",
      "|     model_encdec.decoder.bert.encoder.layer.10.crossattention.self.value.bias     |    768     |\n",
      "|   model_encdec.decoder.bert.encoder.layer.10.crossattention.output.dense.weight   |   589824   |\n",
      "|    model_encdec.decoder.bert.encoder.layer.10.crossattention.output.dense.bias    |    768     |\n",
      "| model_encdec.decoder.bert.encoder.layer.10.crossattention.output.LayerNorm.weight |    768     |\n",
      "|  model_encdec.decoder.bert.encoder.layer.10.crossattention.output.LayerNorm.bias  |    768     |\n",
      "|        model_encdec.decoder.bert.encoder.layer.10.intermediate.dense.weight       |  2359296   |\n",
      "|         model_encdec.decoder.bert.encoder.layer.10.intermediate.dense.bias        |    3072    |\n",
      "|           model_encdec.decoder.bert.encoder.layer.10.output.dense.weight          |  2359296   |\n",
      "|            model_encdec.decoder.bert.encoder.layer.10.output.dense.bias           |    768     |\n",
      "|         model_encdec.decoder.bert.encoder.layer.10.output.LayerNorm.weight        |    768     |\n",
      "|          model_encdec.decoder.bert.encoder.layer.10.output.LayerNorm.bias         |    768     |\n",
      "|       model_encdec.decoder.bert.encoder.layer.11.attention.self.query.weight      |   589824   |\n",
      "|        model_encdec.decoder.bert.encoder.layer.11.attention.self.query.bias       |    768     |\n",
      "|        model_encdec.decoder.bert.encoder.layer.11.attention.self.key.weight       |   589824   |\n",
      "|         model_encdec.decoder.bert.encoder.layer.11.attention.self.key.bias        |    768     |\n",
      "|       model_encdec.decoder.bert.encoder.layer.11.attention.self.value.weight      |   589824   |\n",
      "|        model_encdec.decoder.bert.encoder.layer.11.attention.self.value.bias       |    768     |\n",
      "|      model_encdec.decoder.bert.encoder.layer.11.attention.output.dense.weight     |   589824   |\n",
      "|       model_encdec.decoder.bert.encoder.layer.11.attention.output.dense.bias      |    768     |\n",
      "|    model_encdec.decoder.bert.encoder.layer.11.attention.output.LayerNorm.weight   |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.11.attention.output.LayerNorm.bias    |    768     |\n",
      "|    model_encdec.decoder.bert.encoder.layer.11.crossattention.self.query.weight    |   589824   |\n",
      "|     model_encdec.decoder.bert.encoder.layer.11.crossattention.self.query.bias     |    768     |\n",
      "|     model_encdec.decoder.bert.encoder.layer.11.crossattention.self.key.weight     |   589824   |\n",
      "|      model_encdec.decoder.bert.encoder.layer.11.crossattention.self.key.bias      |    768     |\n",
      "|    model_encdec.decoder.bert.encoder.layer.11.crossattention.self.value.weight    |   589824   |\n",
      "|     model_encdec.decoder.bert.encoder.layer.11.crossattention.self.value.bias     |    768     |\n",
      "|   model_encdec.decoder.bert.encoder.layer.11.crossattention.output.dense.weight   |   589824   |\n",
      "|    model_encdec.decoder.bert.encoder.layer.11.crossattention.output.dense.bias    |    768     |\n",
      "| model_encdec.decoder.bert.encoder.layer.11.crossattention.output.LayerNorm.weight |    768     |\n",
      "|  model_encdec.decoder.bert.encoder.layer.11.crossattention.output.LayerNorm.bias  |    768     |\n",
      "|        model_encdec.decoder.bert.encoder.layer.11.intermediate.dense.weight       |  2359296   |\n",
      "|         model_encdec.decoder.bert.encoder.layer.11.intermediate.dense.bias        |    3072    |\n",
      "|           model_encdec.decoder.bert.encoder.layer.11.output.dense.weight          |  2359296   |\n",
      "|            model_encdec.decoder.bert.encoder.layer.11.output.dense.bias           |    768     |\n",
      "|         model_encdec.decoder.bert.encoder.layer.11.output.LayerNorm.weight        |    768     |\n",
      "|          model_encdec.decoder.bert.encoder.layer.11.output.LayerNorm.bias         |    768     |\n",
      "|                     model_encdec.decoder.cls.predictions.bias                     |   30522    |\n",
      "|            model_encdec.decoder.cls.predictions.transform.dense.weight            |   589824   |\n",
      "|             model_encdec.decoder.cls.predictions.transform.dense.bias             |    768     |\n",
      "|          model_encdec.decoder.cls.predictions.transform.LayerNorm.weight          |    768     |\n",
      "|           model_encdec.decoder.cls.predictions.transform.LayerNorm.bias           |    768     |\n",
      "+-----------------------------------------------------------------------------------+------------+\n",
      "Total Trainable Params: 333029514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "333029514"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params+=param\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "\n",
    "def train_model(model, patience, n_epochs):\n",
    "    epochs = n_epochs\n",
    "    clip = 5\n",
    "    \n",
    "    train_acc_list=[]\n",
    "    val_acc_list=[]\n",
    "    train_loss_list=[]\n",
    "    val_loss_list=[]\n",
    "    train_vencdec_loss_list=[]\n",
    "    val_vencdec_loss_list=[]\n",
    "    train_main_loss_list=[]\n",
    "    val_main_loss_list=[]\n",
    "    \n",
    "        # initialize the experiment path\n",
    "    Path(exp_path).mkdir(parents=True, exist_ok=True)\n",
    "    # initialize early_stopping object\n",
    "    chk_file = os.path.join(exp_path, 'checkpoint_'+exp_name+'.pt')\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True, path=chk_file)\n",
    "\n",
    "\n",
    "    model.train()\n",
    "    for i in range(epochs):\n",
    "        print(f\"******************************EPOCH - {i}****************************************\")\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "        total_vencdec_loss_train = 0\n",
    "        total_main_loss_train = 0\n",
    "        total_train = 0\n",
    "        correct_train = 0\n",
    "\n",
    "        for data in tqdm(dataloader_train, total = len(dataloader_train), desc = \"Mini-batch progress\"):\n",
    "            # print(f'------------------Mini Batch - {mbcnt+1}------------------')\n",
    "            # mbcnt+=1\n",
    "            \n",
    "            \n",
    "            pixel_values_start = time.time()\n",
    "            try:\n",
    "                pixel_values = data['beit_inputs']['pixel_values'].to(device)\n",
    "            except:\n",
    "                print(data)\n",
    "                break\n",
    "            data_time.update(time.time() - pixel_values_start)\n",
    "            if code_prof:\n",
    "                print(f\"pixel_values processing time: {data_time.val}\")\n",
    "            \n",
    "            data_time.reset()\n",
    "            BERT_start = time.time()\n",
    "            BERTtokens = BERTtokenizer(data['bert_inputs'], padding='max_length', truncation=True, max_length=50)\n",
    "\n",
    "            input_ids = torch.tensor(BERTtokens[\"input_ids\"]).to(device)\n",
    "            attention_mask = torch.tensor(BERTtokens[\"attention_mask\"]).to(device)\n",
    "            token_type_ids = torch.tensor(BERTtokens[\"token_type_ids\"]).to(device)\n",
    "            data_time.update(time.time() - BERT_start)\n",
    "            if code_prof:\n",
    "                print(f\"BERT processing time: {data_time.val}\")            \n",
    "            \n",
    "            \n",
    "            data_time.reset()\n",
    "            decoder_labels_start = time.time()\n",
    "            decoder_labels = BERTtokenizer(data['decoder_text'], padding=True, return_tensors=\"pt\").to(device).input_ids\n",
    "            data_time.update(time.time() - decoder_labels_start)\n",
    "            if code_prof:\n",
    "                print(f\"decoder_labels processing time: {data_time.val}\")\n",
    "            \n",
    "            label = data['label'].to(device)\n",
    "            model.zero_grad()\n",
    "            data_time.reset()\n",
    "            model_start = time.time()\n",
    "            vencdec_out = model(pixel_values, input_ids, attention_mask, token_type_ids, decoder_labels)\n",
    "            data_time.update(time.time() - model_start)\n",
    "            if code_prof:\n",
    "                print(f\"model processing time: {data_time.val}\")\n",
    "            \n",
    "            vencdec_loss = vencdec_out.loss\n",
    "            loss = vencdec_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()            \n",
    "\n",
    "            with torch.no_grad():\n",
    "                total_train += label.size(0)\n",
    "                total_vencdec_loss_train += vencdec_loss.item()\n",
    "                total_loss_train += loss.item()\n",
    "\n",
    "        \n",
    "        train_acc = 0\n",
    "        train_loss = 0\n",
    "        train_vencdec_loss = total_vencdec_loss_train/total_train\n",
    "        train_main_loss = 0\n",
    "\n",
    "\n",
    "        # evaluation on validation data phase\n",
    "        model.eval()\n",
    "        total_acc_val = 0\n",
    "        total_loss_val = 0\n",
    "        total_vencdec_loss_val = 0\n",
    "        total_main_loss_val = 0\n",
    "        total_val = 0\n",
    "        correct_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in dataloader_val:                \n",
    "                pixel_values_start = time.time()\n",
    "                pixel_values = data['beit_inputs']['pixel_values'].to(device)\n",
    "                data_time.update(time.time() - pixel_values_start)\n",
    "                if code_prof:\n",
    "                    print(f\"pixel_values processing time: {data_time.val}\")\n",
    "\n",
    "                data_time.reset()\n",
    "                BERT_start = time.time()\n",
    "                BERTtokens = BERTtokenizer(data['bert_inputs'], padding='max_length', truncation=True, max_length=50)\n",
    "\n",
    "                input_ids = torch.tensor(BERTtokens[\"input_ids\"]).to(device)\n",
    "                attention_mask = torch.tensor(BERTtokens[\"attention_mask\"]).to(device)\n",
    "                token_type_ids = torch.tensor(BERTtokens[\"token_type_ids\"]).to(device)\n",
    "                data_time.update(time.time() - BERT_start)\n",
    "                if code_prof:\n",
    "                    print(f\"BERT processing time: {data_time.val}\")            \n",
    "\n",
    "\n",
    "                data_time.reset()\n",
    "                decoder_labels_start = time.time()\n",
    "                decoder_labels = BERTtokenizer(data['decoder_text'], padding=True, return_tensors=\"pt\").to(device).input_ids\n",
    "                data_time.update(time.time() - decoder_labels_start)\n",
    "                if code_prof:\n",
    "                    print(f\"decoder_labels processing time: {data_time.val}\")\n",
    "                \n",
    "                label_val = data['label'].to(device)\n",
    "                model.zero_grad()\n",
    "                data_time.reset()\n",
    "                model_start = time.time()\n",
    "                vencdec_out_val = model(pixel_values, input_ids, attention_mask, token_type_ids, decoder_labels)\n",
    "                data_time.update(time.time() - model_start)\n",
    "                if code_prof:\n",
    "                    print(f\"model processing time: {data_time.val}\")\n",
    "                \n",
    "                vencdec_loss_val = vencdec_out_val.loss\n",
    "                main_loss_val = 0\n",
    "                loss_val = vencdec_loss_val\n",
    "                total_val += label_val.size(0)\n",
    "                total_vencdec_loss_val += vencdec_loss_val.item()\n",
    "                total_main_loss_val = 0\n",
    "                total_loss_val += loss_val.item()\n",
    "                                \n",
    "                \n",
    "        print(\"Saving model...\") \n",
    "        torch.save(model.state_dict(), os.path.join(exp_path, \"final.pt\"))\n",
    "\n",
    "        val_acc = 0\n",
    "        val_loss = 0\n",
    "        val_vencdec_loss = total_vencdec_loss_val/total_val\n",
    "        val_main_loss = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "        train_acc_list.append(train_acc)\n",
    "        val_acc_list.append(val_acc)\n",
    "        train_loss_list.append(train_loss)\n",
    "        val_loss_list.append(val_loss)\n",
    "        train_vencdec_loss_list.append(train_vencdec_loss)\n",
    "        val_vencdec_loss_list.append(total_vencdec_loss_val)\n",
    "        train_main_loss_list.append(train_main_loss)\n",
    "        val_main_loss_list.append(total_main_loss_val)\n",
    "        \n",
    "        early_stopping(val_loss, model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "            \n",
    "        print(f'Epoch {i+1}: train_acc: {train_acc:.4f} | val_acc: {val_acc:.4f} | train_loss: {train_loss:.4f} | val_loss: {val_loss:.4f} | train_vencdec_loss: {train_vencdec_loss:.4f} | val_vencdec_loss: {val_vencdec_loss:.4f} | train_main_loss: {train_main_loss:.4f} | val_main_loss: {val_main_loss:.4f}')\n",
    "        with open(os.path.join(exp_path, exp_name+'_base_exp_results.txt'), 'a+') as of:\n",
    "            of.write(f'Epoch {i+1}: train_acc: {train_acc:.4f} | val_acc: {val_acc:.4f} | train_loss: {train_loss:.4f} | val_loss: {val_loss:.4f} | train_vencdec_loss: {train_vencdec_loss:.4f} | val_vencdec_loss: {val_vencdec_loss:.4f} | train_main_loss: {train_main_loss:.4f} | val_main_loss: {val_main_loss:.4f}\\n')\n",
    "        \n",
    "        model.train()\n",
    "        torch.cuda.empty_cache()\n",
    "    return  model, train_acc_list, val_acc_list, train_loss_list, val_loss_list, train_vencdec_loss_list, val_vencdec_loss_list, train_main_loss_list, val_main_loss_list, i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************EPOCH - 0****************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mini-batch progress:   0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mini-batch progress: 100%|| 313/313 [00:52<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Epoch 1: train_acc: 0.0000 | val_acc: 0.0000 | train_loss: 0.0000 | val_loss: 0.0000 | train_vencdec_loss: 0.6483 | val_vencdec_loss: 0.6126 | train_main_loss: 0.0000 | val_main_loss: 0.0000\n",
      "******************************EPOCH - 1****************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mini-batch progress: 100%|| 313/313 [00:52<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Epoch 2: train_acc: 0.0000 | val_acc: 0.0000 | train_loss: 0.0000 | val_loss: 0.0000 | train_vencdec_loss: 0.3124 | val_vencdec_loss: 0.6138 | train_main_loss: 0.0000 | val_main_loss: 0.0000\n",
      "******************************EPOCH - 2****************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mini-batch progress: 100%|| 313/313 [00:52<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Epoch 3: train_acc: 0.0000 | val_acc: 0.0000 | train_loss: 0.0000 | val_loss: 0.0000 | train_vencdec_loss: 0.2437 | val_vencdec_loss: 0.6049 | train_main_loss: 0.0000 | val_main_loss: 0.0000\n",
      "******************************EPOCH - 3****************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mini-batch progress: 100%|| 313/313 [00:52<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Epoch 4: train_acc: 0.0000 | val_acc: 0.0000 | train_loss: 0.0000 | val_loss: 0.0000 | train_vencdec_loss: 0.1930 | val_vencdec_loss: 0.6242 | train_main_loss: 0.0000 | val_main_loss: 0.0000\n",
      "******************************EPOCH - 4****************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mini-batch progress: 100%|| 313/313 [00:53<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Epoch 5: train_acc: 0.0000 | val_acc: 0.0000 | train_loss: 0.0000 | val_loss: 0.0000 | train_vencdec_loss: 0.1583 | val_vencdec_loss: 0.6606 | train_main_loss: 0.0000 | val_main_loss: 0.0000\n",
      "******************************EPOCH - 5****************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mini-batch progress: 100%|| 313/313 [00:51<00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Epoch 6: train_acc: 0.0000 | val_acc: 0.0000 | train_loss: 0.0000 | val_loss: 0.0000 | train_vencdec_loss: 0.1640 | val_vencdec_loss: 0.6694 | train_main_loss: 0.0000 | val_main_loss: 0.0000\n",
      "******************************EPOCH - 6****************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mini-batch progress: 100%|| 313/313 [00:53<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Epoch 7: train_acc: 0.0000 | val_acc: 0.0000 | train_loss: 0.0000 | val_loss: 0.0000 | train_vencdec_loss: 0.1053 | val_vencdec_loss: 0.6935 | train_main_loss: 0.0000 | val_main_loss: 0.0000\n",
      "******************************EPOCH - 7****************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mini-batch progress: 100%|| 313/313 [00:52<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Epoch 8: train_acc: 0.0000 | val_acc: 0.0000 | train_loss: 0.0000 | val_loss: 0.0000 | train_vencdec_loss: 0.0806 | val_vencdec_loss: 0.7386 | train_main_loss: 0.0000 | val_main_loss: 0.0000\n",
      "******************************EPOCH - 8****************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mini-batch progress: 100%|| 313/313 [00:52<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Epoch 9: train_acc: 0.0000 | val_acc: 0.0000 | train_loss: 0.0000 | val_loss: 0.0000 | train_vencdec_loss: 0.0599 | val_vencdec_loss: 0.7354 | train_main_loss: 0.0000 | val_main_loss: 0.0000\n",
      "******************************EPOCH - 9****************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mini-batch progress: 100%|| 313/313 [00:52<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Epoch 10: train_acc: 0.0000 | val_acc: 0.0000 | train_loss: 0.0000 | val_loss: 0.0000 | train_vencdec_loss: 0.0474 | val_vencdec_loss: 0.7634 | train_main_loss: 0.0000 | val_main_loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "code_prof = False\n",
    "exp_name = \"UM_BEiT_BERT_BERT_role\"\n",
    "exp_path = \"testing/\"+exp_name\n",
    "lr=5e-5\n",
    "# criterion = nn.BCELoss() #Binary case\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "# early stopping patience; how long to wait after last time validation loss improved.\n",
    "patience = 10\n",
    "\n",
    "model, train_acc_list, val_acc_list, train_loss_list, val_loss_list, train_vencdec_loss_list, val_vencdec_loss_list, train_main_loss_list, val_main_loss_list, i = train_model(model, patience, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For deBERTa model\n",
    "def test_model(model):\n",
    "    model.eval()\n",
    "    code_prof = False\n",
    "    generated_result = []\n",
    "    exp1 = []\n",
    "    exp2 = []\n",
    "    ques = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(dataloader_test, 0):               \n",
    "            pixel_values_start = time.time()\n",
    "            pixel_values_test = data['beit_inputs']['pixel_values'].to(device)\n",
    "            data_time.update(time.time() - pixel_values_start)\n",
    "            if code_prof:\n",
    "                print(f\"pixel_values processing time: {data_time.val}\")\n",
    "\n",
    "            BERTtokens = BERTtokenizer(data['bert_inputs'], padding='max_length', truncation=True, max_length=50)\n",
    "\n",
    "            input_ids = torch.tensor(BERTtokens[\"input_ids\"]).to(device)\n",
    "            attention_mask = torch.tensor(BERTtokens[\"attention_mask\"]).to(device)\n",
    "            token_type_ids = torch.tensor(BERTtokens[\"token_type_ids\"]).to(device)\n",
    "            data_time.reset()\n",
    "            decoder_labels_start = time.time()\n",
    "            data_time.update(time.time() - decoder_labels_start)\n",
    "            if code_prof:\n",
    "                print(f\"decoder_labels processing time: {data_time.val}\")\n",
    "            data_time.reset()\n",
    "            model_start = time.time()\n",
    "            bert_encoder_outputs_test = model.model_bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "            \n",
    "            generated_ids = model.model_encdec.generate(pixel_values=pixel_values_test, encoder_outputs=bert_encoder_outputs_test, max_length=150, num_beams = 2, repetition_penalty = 2.5, length_penalty = 1.0)\n",
    "            preds = [BERTtokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
    "            print(preds)\n",
    "            generated_result.extend(preds)\n",
    "            exp1.extend(data[\"decoder_text\"])\n",
    "            exp2.extend(data[\"decoder_text1\"])  \n",
    "            ques.extend(data[\"bert_inputs\"])\n",
    "    return generated_result, exp1, exp2, ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2286447/1761090260.py:33: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  self.samples_frame.image = self.samples_frame.apply(\n"
     ]
    }
   ],
   "source": [
    "test_path = \"ANONYMISED\"\n",
    "hm_dataset_test = HarmemeMemesDatasetAug(test_path, data_dir, mode = \"test\")\n",
    "dataloader_test = DataLoader(hm_dataset_test, batch_size=BS,\n",
    "                        shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siddhant20247/ENTER/envs/py39/lib/python3.9/site-packages/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['answer : hillary clinton because hilary clinton is framed as a whiner', 'answer : donald trump because donald trump is portrayed as being incompetent', 'answer : donald trump because donald trump is portrayed as unintelligent', \"answer : barack obama because barack obama's presidency is portrayed as being catastrophic\"]\n",
      "['answer : shrek super party because shrek super party is shown as a suitable option', 'answer : xi jinping because xi jinping is depicted to be interfering with american politics', 'answer : democrats because the democrats are portrayed to have colluded with foreing interests', 'answer : america because amercia is portrayed to have suffered due to a bad president']\n",
      "['answer : barack obama because barack obama is portrayed as classy', 'answer : donald trump because donald trump is insinuated as the worst president in hisptry', 'answer : donald trump because donald trump is insinuated as hateful', 'answer : people because the people are portrayed as being exploited']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['answer : democratic party because the democratic party is framed as manipulative', 'answer : democratic party because the democratic party is depicted as hateful', 'answer : democratic party because the democratic party is depicted as supporting hate groups', 'answer : democratic party because the democratic party is portrayed as a repulsive option']\n",
      "['answer : democrats because the democrats are portrayed as being demonic', 'answer : joe biden because joe biden is portrayed as being inappropriate with young children', 'answer : stacy abrams because stacy abrams is portrayed as an unfavourable leader', 'answer : joe biden because joe biden is portrayed as an unfavourable leader']\n",
      "['answer : democratic party because the democratic party is portrayed as being full of hateful people', 'answer : donald trump because donald trump is framed as incompetent', 'answer : kkk because kkk is referred as a hate group', 'answer : democratic party because the democratic party is portrayed as spreading misinformation']\n",
      "['answer : libertarian party because the libertarian party is portrayed as having double standards', 'answer : donald trump because donald trump is portrayed as hateful', 'answer : democratic party because the democratic party is portrayed as hateful', 'answer : democratic party because the democratic party is framed as a conspiracy']\n",
      "['answer : democratic party because the democratic party is framed as being clueless', 'answer : democratic party because the democratic party is portrayed as having an unfavourable ideology', 'answer : alexandria ocasio - cortez because alexandria ocasio - cortez is portrayed as unfavourable', 'answer : capitalist democrats because capitalist democrats are portrayed as being unsuitable for the party']\n",
      "['answer : poor kids because poor kids are portrayed as being inappropriately touched', 'answer : the new york times because the new york times is depicted as biased', 'answer : democratic party because the democratic party is portrayed to have communist ideologies', 'answer : democratic party because the democratic party is framed as a conspiracy']\n",
      "['answer : democratic party because the democratic party is insinuated as hateful', 'answer : america because america is portrayed as being under danger', 'answer : donald trump because donald trump is portrayed as hateful', 'answer : democratic party because the democratic party is portrayed as being against diversity']\n",
      "['answer : democrats because the democrats are framed as hypocrites', 'answer : lgbtq + because lbgtq + people are portrayed as being denied their rights', 'answer : democratic party because the democratic party is portrayed as supportive of underrepresented communities', 'answer : america because america is portrayed as being under danger']\n",
      "['answer : donald trump because donald trump is framed as a racist', 'answer : kamala harris because kamala harris is portrayed as problematic', 'answer : kamala harris because kamala harris is portrayed as the ideal choice', 'answer : government because the government is portrayed as dangerous']\n",
      "['answer : democrats because the democrats are portrayed as having double standards', 'answer : alexandria ocasio - cortez because alexandria ocasio - cortez is depicted as an unfavourable leader', 'answer : democratic party because the democratic party is portrayed as being full of hateful people', 'answer : democratic party because the democratic party is framed as having double standards']\n",
      "['answer : barack obama because barack obama is framed as a fraud', 'answer : racists because black people are framed as having racial discrimination', 'answer : democratic party because the democratic party is framed as spreading social unrest', 'answer : black people because black people are portrayed as being targetted']\n",
      "['answer : democratic party because the democratic party is portrayed as a repulsive option', 'answer : hillary clinton because hilary clinton is portrayed as unintelligent', 'answer : democratic party because the democratic party is portrayed as spreading misinformation', 'answer : democratic party because the democratic party is portrayed as being influenced by corporate money']\n",
      "['answer : donald trump because donald trump is portrayed as being targetted', 'answer : democratic party because the democratic party is framed as racist', 'answer : hillary clinton because hilary clinton is portrayed as being responsible for the destruction of the democratic party', 'answer : democratic party because the democratic party is framed as engaging in unpleasant work']\n",
      "['answer : republican party because the republican party is portrayed as an unfavourable choice', 'answer : joe biden because joe biden is portrayed as inappropriate', 'answer : democratic party because the democratic party is portrayed as being filled with undesirable politicians', 'answer : alexandria ocasio - cortez because alexandria ocasio - cortez is depicted as unfavourable']\n",
      "['answer : joe biden because joe biden is portrayed as self - absorbed', 'answer : donald trump because donald trump is portrayed as unfavourable', 'answer : black people because black people are portrayed as being targetted', 'answer : joe biden because joe biden is portrayed as inappropriate']\n",
      "['answer : donald trump because donald trump is portrayed as an unfavourable choice', 'answer : green party because the green party is framed as corrupt', 'answer : jill stein because jill stein is portrayed as a hypocrite', 'answer : green party because the green party is shown as considerate of the environment']\n",
      "['answer : investigative journalism because investigative journalism is portrayed as unintelligent', 'answer : alt - - left because alt - left is depicted as a wrong choice', 'answer : poor people because poor people are portrayed as unwilling to accept their faults', 'answer : capitalism because capitalism is depicted as being wrongly targeted']\n",
      "['answer : democratic party because the democratic party is portrayed as hateful', 'answer : jill stein because jill stein is portrayed as a hypocrite', 'answer : green party because the green party is portrayed as disruptive', 'answer : government because the government is framed as inconsiderate of public health']\n",
      "['answer : climate change because climate change is portrayed as an important issue', 'answer : joe biden because joe biden is portrayed as inappropriate', 'answer : joe biden because joe biden is portrayed as inadequate for a medal', 'answer : garry johnson because gary johnson is lauded as responsible']\n",
      "['answer : hillary clinton because hillary clinton is framed as covering up her crimes', 'answer : donald trump because donald trump is framed as a racist', 'answer : guns because guns are portrayed as useless', 'answer : barack obama because barack obama is portrayed as cool']\n",
      "['answer : libertarians because libertarians are portrayed as being hypocrties', 'answer : libertarian party because the libertarian party is portrayed as considerate of freedom', 'answer : donald trump because donald trump is portrayed as hateful', 'answer : donald trump because donald trump is portrayed as hateful']\n",
      "['answer : donald trump because donald trump is portrayed as hateful', 'answer : donald trump because donald trump is portrayed as hateful', 'answer : hillary clinton because hilary clinton is portrayed as unintelligent', 'answer : gary johnson because gary johnson is portrayed as responsible']\n",
      "['answer : libertarian party because the libertarian party is portrayed as considerate of the environment', 'answer : war because war is portrayed as an unfavourable choice', 'answer : people because people are portrayed as being oppressed', 'answer : barack obama because barack obama is portrayed as honouring rapists']\n",
      "['answer : donald trump because donald trump is portrayed as unfavourable', 'answer : donald trump because donald trump is insinuated as the worst president in history', 'answer : donald trump because donald trump is insinuated as the worst president in history', 'answer : donald trump because donald trump is insinuated as the worst president in history']\n",
      "['answer : republican party because the republican party is portrayed as conspiring against a political leader', 'answer : libertarian party because the libertarian party is portrayed as a suitable option', 'answer : democratic party because the democratic party is portrayed as engaging in unpleasant work', 'answer : leftists because leftists are portrayed as stupid']\n",
      "['answer : libertarian party because the libertarian party is portrayed as being influenced by corporate money', 'answer : democratic party because the democratic party is portrayed as being clueless', 'answer : social safety nets because social safety nets are portrayed as a trap', 'answer : libertarian party because the libertarian party is portrayed as negligent']\n",
      "[\"answer : democrats because the democrats are portrayed as working against the country's interests\", 'answer : libertarians because the libertarians are portrayed as being historically ideal', 'answer : social safety nets because social safety nets are portrayed as a trap', 'answer : libertarians because libertarians are portrayed as having unfavourable beliefs']\n",
      "['answer : regulation because regulation is portrayed as an unwelcome association', 'answer : people because the people are portrayed as being in danger', 'answer : state governors because state governors are portrayed as responsible for many deaths', 'answer : citizens because citizens are portrayed as being oppressed']\n",
      "['answer : libertarians because the libertarians are portrayed as having unfavourable beliefs', 'answer : government because the government is framed as inefficient', 'answer : joe biden because joe biden is lauded as a hope for change', 'answer : libertarian party because the libertarian party is portrayed as having an unfavourable ideology']\n",
      "['answer : libertarian party because the libertarian party is portrayed as a scam', 'answer : libertarian party candidates because libertarian party candidates are depicted as strange', 'answer : democratic party because the democratic party is shown as an unfavourable option', 'answer : radical islam because radical islam is shown as causing social unrest']\n",
      "['answer : democratic party because the democratic party is shown as an unfavourable option', 'answer : gary johnson because gary johnson is portrayed as a favourable candidate', 'answer : libertarian party because the libertarian party is depicted as ignorant', 'answer : fbi because the fbi is portrayed as the biggest threat to the country']\n",
      "['answer : democrats because the democrats are portrayed as racist', 'answer : american people because the american people are portrayed as being misrepresented', 'answer : mike pence because mike pence is portrayed as unintelligent', 'answer : republican party because the republican party is portrayed as being filled with hateful people']\n",
      "['answer : republican party because the republican party is portrayed as hateful', 'answer : republican party because the republican party is shown as being attacked by a politician', 'answer : donald trump because donald trump is portrayed as unfavourable', 'answer : republican party because the republican party is portrayed as repulsive']\n",
      "['answer : national security agency ( nsa ) because national securty agency ( nsa ) is portrayed as intrusive', 'answer : war because war is portrayed as a racket', 'answer : republican party because the republican party is portrayed as deranged', 'answer : republican party because the republican party is portrayed as unsuitable to vote for']\n",
      "['answer : libertarian party because the libertarian party is portrayed as supportive of freedom', 'answer : democrats because the democrats are portrayed as having double standards', 'answer : donald trump because donald trump is portrayed as hateful', 'answer : democratic party because the democratic party is shown as an unsuitable option']\n",
      "['answer : republican party because the republic party is shown as an unsuitable option', 'answer : donald trump because donald trump is framed as a liar', 'answer : labour party because the labour party is framed as corrupt', 'answer : people because people are portrayed as being oppressed']\n",
      "['answer : adolf hitler because adolf hitler is portrayed as having an unsuitable ideology', 'answer : adolf hitler because adolf hitler is portrayed as having an unsuitable ideology', 'answer : democratic party because the democratic party is portrayed as a repulsive option', 'answer : hillary clinton because hilary clinton is portrayed as provoking a war']\n",
      "['answer : the new york times because the new york times is depicted as biased', 'answer : donald trump because donald trump is portrayed as unfavourable', 'answer : donald trump because donald trump is portrayed as unfavourable', 'answer : mainstream media because the mainstream media is depicted as being biased against third party']\n",
      "['answer : conservatives because conservatives are portrayed as unfavourable', 'answer : valdimir putin because vladimir putin is portrayed as interfering in american politics', 'answer : democratic party because the democratic party is framed as inconsiderate of the environment', 'answer : democratic party because the democratic party is shown as hateful']\n",
      "['answer : children because children are portrayed as being kidnapped', 'answer : hillary clinton because hillary clinton is portrayed as inappropriate', 'answer : hillary clinton because hillary clinton is portrayed as classy', 'answer : republican party because the republican party is portrayed as being influenced by foreign actors']\n",
      "['answer : democratic party because the democratic party is framed as inconsiderate of the environment', 'answer : democratic party because the democratic party is accused of neglecting national security', 'answer : joe biden because joe biden is depicted as the ideal candiate', 'answer : donald trump because donald trump is framed as an impostor']\n",
      "['answer : valdirmir putin because vladmir putin is portrayed as interfering in american politics', 'answer : republican party because the republic party is portrayed as being under foreign control', \"answer : america because america's security is portrayed as being neglected\", 'answer : democratic party because the democratic party is insinuated as an unfavourable option']\n",
      "['answer : democratic party because the democratic party is framed as having double standards', 'answer : gop because the gop is depicted as inconsiderate of the environment', 'answer : america because america is portrayed as being under threat', 'answer : valdimir putin because vladimir putin is insinuated as the worst president in history']\n",
      "['answer : green party because the green party is portrayed as considerate of the environment', 'answer : donald trump because donald trump is portrayed as hateful', 'answer : republican party because the republican party is shown as disintegrating', 'answer : donald trump because donald trump is portrayed as inconsiderate of the environment']\n",
      "['answer : donald trump because donald trump is shown as undesirable', 'answer : libertarian party because the libertarian party is portrayed as condescending', 'answer : radical islam because radical islam is portrayed as violent', 'answer : democracy because the democracy is portrayed as being in danger']\n",
      "['answer : muslim because muslims are portrayed as being targetted', 'answer : republican party because the republican party is portrayed as repulsive', 'answer : donald trump because donald trump is portrayed as unhelpful to the people', 'answer : donald trump supporter because donald trump supporter is portrayed as unintelligent']\n",
      "['answer : democratic party because the democratic party is portrayed as spreading misinformation', 'answer : barack obama because barack obama is lauded for being honest', 'answer : joe biden because joe biden is framed as having engaged in altering election results', 'answer : donald trump because donald trump is framed as a racist']\n",
      "['answer : donald trump because donald trump is framed as having undesirable qualities', 'answer : pat quinn because pat quinn is framed as a sexual assualter', 'answer : republican party because the republican party is portrayed as inconsiderate of public health', 'answer : poor people because poor people are portrayed as being neglected']\n",
      "['answer : libertarian party because the libertarian party is portrayed as exploitative', 'answer : democrats because the democrats are shown as representatives of oligarchy', 'answer : libertarians because libertarians are portrayed as the ideal', 'answer : republican party because the republican party is portrayed as dangerous']\n",
      "['answer : joe biden because joe biden is portrayed as inappropriate', 'answer : republican party because the republican party is portrayed as unattractive', 'answer : joe biden because joe biden is portrayed as inappropriate', 'answer : joe biden because joe biden is portrayed as inappropriate']\n",
      "['answer : libertarian party because the libertarian party is portrayed as supportive of slavery', 'answer : democrats because the democrats are portrayed to have supported slavery', 'answer : mexican because the mexican people are portrayed as being underrepresented', 'answer : conservatives because conservatives are portrayed as being targetted']\n",
      "['answer : donald trump because donald trump is portrayed as being oppressive to minorities', 'answer : people because the people are portrayed as suffering', 'answer : muslims because muslims are portrayed as being oppressed', 'answer : people because people are portrayed as being neglected']\n",
      "['answer : leftists because leftists are portrayed as being targetted', 'answer : mexicans because mexicans are portrayed as being targetted', 'answer : trump presidency because the trump presidency is framed as being incompetent', 'answer : donald trump because donald trump is portrayed as being unfavourable']\n",
      "['answer : fascist because a fascist is portrayed as disgusting', 'answer : mitch mcconnell because mitch mcconnell is portrayed as unintelligent', 'answer : republican party because the republican party is framed as corrupt', 'answer : republican party because the republican party is framed as corrupt']\n",
      "['answer : communism because communism is portrayed as inefficient', 'answer : denmark because denmark is portrayed as a great place to live in', 'answer : republican party because the republican party is framed as racist', 'answer : george soros because george soros is portrayed as unhelpful to the people']\n",
      "['answer : america because america is portrayed as being under danger', 'answer : donald trump because donald trump is framed as a bad representative of the country', 'answer : donald trump because donald trump is portrayed as an unfavourable choice', 'answer : donald trump because donald trump is framed as a bad representative of the country']\n",
      "['answer : conservatives because conservatives are portrayed as having unfavourable beliefs', \"answer : libertarian party because the libertarian party is portrayed as considerate of people's freedom\", 'answer : donald trump because donald trump is portrayed as an unsuitable choice', 'answer : donald trump because donald trump is portrayed as unintelligent']\n",
      "['answer : donald trump because donald trump is portrayed as unfavourable', 'answer : donald trump because donald trump is portrayed as unfavourable', 'answer : green party because the green party is shown as an unfavourable choice', 'answer : hillary clinton because hilary clinton is framed as a bad leader']\n",
      "['answer : green party because the green party is framed as conspiring to disrupt a political event', 'answer : joe biden because joe biden is portrayed as being inappropriate with young children', 'answer : joe biden because joe biden is portrayed as being mocked for his advanced age', 'answer : donald trump because donald trump is portrayed as unintelligent']\n",
      "['answer : donald trump because donald trump is framed as a racist', 'answer : barack obama because barack obama is depicted as honouring his country', 'answer : joe biden because joe biden is portrayed as touching inappropriately', 'answer : joe biden because joe biden is portrayed as an unfavourable choice for the elections']\n",
      "['answer : joe biden because joe biden is portrayed as an unfavourable choice for the elections', 'answer : joe biden because joe biden is portrayed as spreading misinformation', 'answer : joe biden because joe biden is framed as an impostor', 'answer : joe biden because joe biden is portrayed as inappropriate']\n",
      "['answer : joe biden because joe biden is portrayed as an unfavourable choice for the elections', 'answer : joe biden because joe biden is portrayed as unintelligent', 'answer : libertarian party because the libertarian party is framed as corrupt', 'answer : hillary clinton because hilary clinton is portrayed as unfavourable']\n",
      "['answer : joe biden because joe biden is framed as incompetent', 'answer : joe biden because joe biden is portrayed as childish', 'answer : joe biden because joe biden is portrayed as unintelligent', 'answer : joe biden because joe biden is portrayed as being inappropriate with young children']\n",
      "['answer : libertarian party because the libertarian party is portrayed as negligent', 'answer : joe biden because joe biden is framed as a sexual assualter', 'answer : democrats because the democrats are portrayed to have damaged the reputation of the party', 'answer : australian labor party because the australian labor party is portrayed as being conspired against']\n",
      "['answer : george soros because george soros is framed as conspiring to increase racial tensions', 'answer : conservative because a conservative is shown as the ideal candidate', 'answer : conservative because a conservative is shown as corrupt', 'answer : progressive insurance because progressive insurance is portrayed as being inconsiderate of public health']\n",
      "['answer : joe biden because joe biden is portrayed as inappropriate', 'answer : communism because communism is framed as an unfavourable choice', 'answer : government because the government is framed as incompetent', 'answer : capitalism because capitalism is portrayed as being sold']\n",
      "['answer : californians because californians are portrayed as inefficient', 'answer : radical islam because radical islam is shown as having unfavourable ideology', 'answer : muslims because muslims are portrayed as being targetted politically', 'answer : donald trump because donald trump is framed as a racist']\n",
      "['answer : donald trump because donald trump is portrayed as being wrongly accused of racism', 'answer : donald trump because donald trump is portrayed as oppressive', 'answer : people because people are portrayed as being threatened', 'answer : america because american is portrayed as being in danger']\n",
      "['answer : donald trump because donald trump is portrayed as undoing the progress of his predecessor', 'answer : joe biden because joe biden is portrayed as making ill - suited comments', 'answer : muslims because muslims are portrayed as being opressed', 'answer : donald trump because donald trump is portrayed as being dangerous']\n",
      "['answer : jill stein because jill stein is portrayed as spreading misinformation', 'answer : donald trump because donald trump is portrayed as the greatest threat to the country', 'answer : donald trump because donald trump is portrayed as an unfavourable choice', 'answer : donald trump because donald trump is framed as a racist']\n",
      "['answer : donald trump because donald trump is portrayed as a racist', 'answer : adolf hitler because adolf hitler is portrayed as having an unsuitable ideology', 'answer : adolf hitler because adolf hitler is portrayed as being treated inappropriately', 'answer : adolf hitler because adolf hitler is portrayed as having an unsuitable ideology']\n",
      "['answer : donald trump because donald trump is insinuated as unintelligent', 'answer : adolf hitler because adolf hitler is portrayed as having an unsuitable ideology', 'answer : donald trump because donald trump is portrayed as an unfavourable choice', 'answer : barack obama because barack obama is portrayed as being treated unfairly']\n",
      "['answer : donald trump because donald trump is framed as a bad leader', 'answer : america because america is portrayed as being conspired against', 'answer : victimless crime because victimless crime is portrayed as being neglected', 'answer : democracy because the democracy is portrayed as being hypocrites']\n",
      "['answer : barack obama because barack obama is portrayed as untrustworthy', 'answer : barack obama because barack obama is depicted as cool', 'answer : donald trump because donald trump is portrayed as being insulted', \"answer : donald trump because donald trump's loss is portrayed as being celebrated\"]\n"
     ]
    }
   ],
   "source": [
    "generated_result, ref1, ref2, ques = test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {\"hyp\" : generated_result, \"ref1\" : ref1, \"ref2\" : ref2, \"ques\" : ques}\n",
    "\n",
    "df1 = pd.DataFrame(dict)\n",
    "df1.to_csv(exp_name +  \".csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
