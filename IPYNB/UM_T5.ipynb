{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## UM T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GumUgRkqomaQ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn.functional as F\n",
    "from torch import optim, nn\n",
    "from torchvision import models, transforms\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G53ygiIBpALH"
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW, Adafactor\n",
    "import os, sys\n",
    "sys.path.append('/workout/early-stopping-pytorch')\n",
    "from pytorchtools import EarlyStopping\n",
    "from tqdm import tqdm,trange\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1SrkGKp9qHUe"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\",\n",
    "                                             return_dict=True)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemeMQACorpus(torch.utils.data.Dataset):\n",
    "    \"\"\"Uses jsonl data to preprocess and serve \n",
    "    dictionary of multimodal tensors for model input.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path,\n",
    "        img_dir,\n",
    "        mode=None,\n",
    "        balance=False,\n",
    "        dev_limit=None,\n",
    "        random_state=0,\n",
    "    ):\n",
    "\n",
    "        self.samples_frame = pd.read_json(\n",
    "            data_path\n",
    "        )\n",
    "        \n",
    "        self.samples_frame = self.samples_frame[self.samples_frame[\"meme_image\"].notnull()]\n",
    "        self.samples_frame = self.samples_frame[self.samples_frame[\"ocr\"].notnull()]\n",
    "        self.samples_frame = self.samples_frame[self.samples_frame[\"entity\"].notnull()]\n",
    "        self.samples_frame = self.samples_frame[self.samples_frame[\"explanation\"].notnull()]\n",
    "        if mode == \"test\":\n",
    "            self.samples_frame = self.samples_frame[self.samples_frame[\"explanation1\"].notnull()]\n",
    "\n",
    "\n",
    "        self.samples_frame = self.samples_frame.reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "        self.samples_frame.image = self.samples_frame.apply(\n",
    "            lambda row: (img_dir + '/' + row.meme_image), axis=1\n",
    "        )\n",
    "        \n",
    "        self.image_transform = Resize((256,256))\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"This method is called when you do len(instance) \n",
    "        for an instance of this class.\n",
    "        \"\"\"\n",
    "        return len(self.samples_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"This method is called when you do instance[key] \n",
    "        for an instance of this class.\n",
    "        \"\"\"\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = self.samples_frame.loc[idx, \"meme_image\"]  \n",
    "        text_inputs = self.samples_frame.loc[idx, \"question\"]  + \"\\n Options: \" + self.samples_frame.loc[idx, \"optC\"] + \"\\nContext: \" + self.samples_frame.loc[idx, \"ocr\"]        \n",
    "        decoder_text = \"Answer: \" + self.samples_frame.loc[idx, \"entity\"] + \" BECAUSE \" + self.samples_frame.loc[idx, \"explanation\"] + '</s>'\n",
    "        sample = {\n",
    "                \"img_name\": img_name,        \n",
    "                \"text_inputs\": text_inputs,\n",
    "                \"decoder_text\": decoder_text\n",
    "            }\n",
    "        try:\n",
    "            sample[\"decoder_text1\"] = \"Answer: \" + self.samples_frame.loc[idx, \"entity\"] + \" BECAUSE \" + self.samples_frame.loc[idx, \"explanation1\"]\n",
    "        except:\n",
    "            pass\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3y9kUAVpquHu"
   },
   "outputs": [],
   "source": [
    "BS = 4\n",
    "train_path = \"ANONYMISED\"\n",
    "dev_path = \"ANONYMISED\"\n",
    "data_dir = \"ANONYMISED\"\n",
    "hm_dataset_train = MemeMQACorpus(train_path, data_dir)\n",
    "dataloader_train = DataLoader(hm_dataset_train, batch_size=BS,\n",
    "                        shuffle=True, num_workers=0)\n",
    "hm_dataset_val = MemeMQACorpus(dev_path, data_dir)\n",
    "dataloader_val = DataLoader(hm_dataset_val, batch_size=BS,\n",
    "                        shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm_dataset_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yquir4_-qvnj"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "data_time = AverageMeter('Data', ':6.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params+=param\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "    \n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sJI_YG0ys20U"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "def train_model(model, n_epochs):\n",
    "  epochs = n_epochs\n",
    "  train_loss_list = []\n",
    "  val_loss_list = []\n",
    "  Path(exp_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "  model.train()\n",
    "  for i in range(epochs):\n",
    "    print(f\"******************************EPOCH - {i}****************************************\")\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "\n",
    "    for data in tqdm(dataloader_train, total = len(dataloader_train), desc = \"Mini-batch progress\"):\n",
    "      input_tokens = tokenizer.batch_encode_plus(data['text_inputs'],padding=True,max_length=400,return_tensors='pt')\n",
    "      input_ids = input_tokens.input_ids.to(device)\n",
    "      decoder_labels = tokenizer.batch_encode_plus(data['decoder_text'],padding=True,max_length=400,return_tensors='pt').input_ids.to(device)\n",
    "      optimizer.zero_grad()\n",
    "      model_out = model(input_ids=input_ids, labels=decoder_labels)\n",
    "      loss = model_out.loss\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      with torch.no_grad():\n",
    "        train_loss += loss.item()\n",
    "      \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader_val: \n",
    "            input_tokens = tokenizer.batch_encode_plus(data['text_inputs'],padding=True,max_length=400,return_tensors='pt')\n",
    "            input_ids = input_tokens.input_ids.to(device)\n",
    "            decoder_labels = tokenizer.batch_encode_plus(data['decoder_text'],padding=True,max_length=400,return_tensors='pt').input_ids.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            model_out_val = model(input_ids=input_ids, labels=decoder_labels)\n",
    "            val_loss += model_out_val.loss\n",
    "    print(\"Saving model...\")\n",
    "    torch.save(model.state_dict(), os.path.join(exp_path, \"epoch\" + str(i) + \"final.pt\"))\n",
    "    train_loss_list.append(train_loss)\n",
    "    val_loss_list.append(val_loss)\n",
    "    print(f'Epoch {i+1}: train_loss: {train_loss:.4f} | val_loss: {val_loss:.4f}')\n",
    "    with open(os.path.join(exp_path, exp_name+'_base_exp_results.txt'), 'a+') as of:\n",
    "      of.write(f'Epoch {i+1}: train_loss: {train_loss:.4f} | val_loss: {val_loss:.4f}')\n",
    "    model.train()\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "  return model, train_loss_list, val_loss_list, i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "qeo-dVx8sGV8",
    "outputId": "94cf8d13-a801-45dd-954e-0df28eb4d0ac"
   },
   "outputs": [],
   "source": [
    "code_prof = False\n",
    "\n",
    "exp_name = \"UM_TEXT_T5_Role\"\n",
    "exp_path = \"testing/\"+exp_name\n",
    "\n",
    "lr=0.0001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adafactor(model.parameters(),lr=1e-3,\n",
    "                      eps=(1e-30, 1e-3),\n",
    "                      clip_threshold=1.0,\n",
    "                      decay_rate=-0.8,\n",
    "                      beta1=None,\n",
    "                      weight_decay=0.0,\n",
    "                      relative_step=False,\n",
    "                      scale_parameter=False,\n",
    "                      warmup_init=False)\n",
    "n_epochs = 10\n",
    "\n",
    "model, train_loss_list, val_loss_list, i = train_model(model, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    generated = []\n",
    "    exp1 = []\n",
    "    exp2 = []\n",
    "    ques = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader_test: \n",
    "            input_tokens = tokenizer.batch_encode_plus(data['text_inputs'],padding=True,max_length=400,return_tensors='pt').to(device)\n",
    "            outputs = model.generate(input_tokens.input_ids)\n",
    "            output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "            generated.extend(output_str)\n",
    "            exp1.extend(data[\"decoder_text\"])\n",
    "            exp2.extend(data[\"decoder_text1\"])\n",
    "            ques.extend(data[\"text_inputs\"])\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return generated, exp1, exp2, ques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"../data/data_test_role.json\"\n",
    "\n",
    "hm_dataset_test = HarmemeMemesDatasetAug(test_path, data_dir, mode = \"test\")\n",
    "dataloader_test = DataLoader(hm_dataset_test, batch_size=BS,\n",
    "                        shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_result, ref1, ref2, ques = test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(generated_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {\"hyp\" : generated_result, \"ref1\" : ref1, \"ref2\" : ref2, \"ques\" : ques}\n",
    "df1 = pd.DataFrame(dict)\n",
    "df1.to_csv(exp_name +  \".csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
